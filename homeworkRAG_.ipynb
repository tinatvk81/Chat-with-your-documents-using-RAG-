{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy9xEHmjUadt",
        "outputId": "dfe97050-2948-4140-9ecd-daafb361d53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_community\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n",
            "  Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n",
            "  Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.75-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (2.7.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.12.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, tiktoken, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.3 langchain-core-0.2.5 langchain-text-splitters-0.2.1 langchain_community-0.2.4 langsmith-0.1.75 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqqSJ7CpPJRU",
        "outputId": "1b327869-8105-4552-a4dd-c3f9e5916d0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu121\n",
            "Collecting llama-cpp-python\n",
            "  Downloading https://github.com/abetlen/llama-cpp-python/releases/download/v0.2.77-cu121/llama_cpp_python-0.2.77-cp310-cp310-linux_x86_64.whl (326.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.6/326.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.1)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.77\n"
          ]
        }
      ],
      "source": [
        "%pip install -q langchainhub langchain_chroma datasets langchain chromadb\n",
        "!pip install sentence-transformers\n",
        "!pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zqRuMmQLx8j",
        "outputId": "939dd7fe-624a-49a4-9422-7bc8343c9771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.0.60-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-community<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.2.4)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from langchain_experimental) (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.2.3)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (0.1.75)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community<0.3,>=0.2->langchain_experimental) (8.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2->langchain_experimental) (2.7.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.3,>=0.2->langchain_experimental) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2->langchain_experimental) (2.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community<0.3,>=0.2->langchain_experimental) (0.2.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<0.3,>=0.2->langchain_experimental) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2->langchain_experimental) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community<0.3,>=0.2->langchain_experimental) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community<0.3,>=0.2->langchain_experimental) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.3,>=0.2->langchain_experimental) (1.0.0)\n",
            "Installing collected packages: langchain_experimental\n",
            "Successfully installed langchain_experimental-0.0.60\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pR8qOPCaRfgl",
        "outputId": "925d8d19-090b-466c-a5ae-bf7bd9f57842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from PyPDF) (4.12.1)\n",
            "Installing collected packages: PyPDF\n",
            "Successfully installed PyPDF-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HJBTLbtSHLx7"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "# from langchain_openai.embeddings import OpenAIEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9yr6qctnl4A"
      },
      "source": [
        "#  Section 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yIQNAXi8nO1s"
      },
      "outputs": [],
      "source": [
        "# from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "\n",
        "# hf = HuggingFacePipeline.from_model_id(\n",
        "#     model_id=\"TheBloke/Mistral-7B-OpenOrca-GGUF\", task=\"text-generation\", pipeline_kwargs={\"max_new_tokens\": 200, \"pad_token_id\": 50256},\n",
        "# )\n",
        "\n",
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "# template = \"\"\"Question: {question}\n",
        "\n",
        "# Answer: Let's think step by step.\"\"\"\n",
        "# prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# chain = prompt | hf\n",
        "\n",
        "# question = \"What is electroencephalography?\"\n",
        "\n",
        "# print(chain.invoke({\"question\": question}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r3Jy6sX04_f_"
      },
      "outputs": [],
      "source": [
        "# !CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "562963851f564cdba383a9c4be90016c",
            "04ad1d1452b64542a0cefca03260a8f8",
            "98e637ae57174f21927145d2d210ec57",
            "bd932ec714f54e41b61819bbc9be2a9b",
            "df2cd4e7a0e641ebadc34f5980389af6",
            "f4e0613ef28e45bb8accee36e0fc27bd",
            "65cfcd8af0e1430d8374b30e258462e8",
            "4a1e6b2ecda647839bf9d6518b861757",
            "e461879d1ae14048ac407bbbcac7da77",
            "8c7e245824e648c3a6b5658435471623",
            "45b4b5d4ee3e46f396a5003bf348e5a0"
          ]
        },
        "id": "3zOWnILq44HA",
        "outputId": "9d72376b-9ccd-4e2e-ca39-b675dcb75d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "mistral-7b-openorca.Q8_0.gguf:   0%|          | 0.00/7.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "562963851f564cdba383a9c4be90016c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My model path:  /content/mistral-7b-openorca.Q8_0.gguf\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "# from llama_cpp import Llama\n",
        "from langchain_community.llms import LlamaCpp\n",
        "model_name = \"TheBloke/Mistral-7B-OpenOrca-GGUF\"\n",
        "model_file = \"mistral-7b-openorca.Q8_0.gguf\"\n",
        "HF_TOKEN = \"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\"\n",
        "model_path = hf_hub_download(model_name,\n",
        "                             filename=model_file,\n",
        "                             local_dir='/content',\n",
        "                             token=HF_TOKEN)\n",
        "print(\"My model path: \", model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mak_exl7-0e",
        "outputId": "f35bf74d-5cca-48c0-d69b-f17ed800ffed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /content/mistral-7b-openorca.Q8_0.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = open-orca_mistral-7b-openorca\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
            "llama_model_loader: - kv  11:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32002]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32002]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 32000\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special tokens cache size = 261\n",
            "llm_load_vocab: token to piece cache size = 0.1637 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32002\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 7.24 B\n",
            "llm_load_print_meta: model size       = 7.17 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = open-orca_mistral-7b-openorca\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 32000 '<dummy32000>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   yes\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   132.82 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  7205.84 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 800\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   100.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  100.00 MiB, K (f16):   50.00 MiB, V (f16):   50.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =     5.22 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =     0.60 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '32000', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'open-orca_mistral-7b-openorca', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "# from llama_cpp import Llama\n",
        "llm = LlamaCpp(model_path=model_path,n_gpu_layers=-1,n_ctx=800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3CR-kda-8FTO"
      },
      "outputs": [],
      "source": [
        "# response = llm(\"What is an LLM?\", max_tokens=1000)\n",
        "# response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63id9dyA_D2Y"
      },
      "source": [
        "# Section 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZStiEoybAcVu"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "text=\"\"\n",
        "loader = PyPDFLoader(\"/content/1.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "for page in pages:\n",
        "            text += page.page_content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "Eoo-ARe8KZy7",
        "outputId": "a908d58b-ca13-4b3e-b1e0-cd9d91bd252e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Operating R. Stockton Gaines \\nSystems Editor \\nPassword Security: \\nA Case History \\nRobert Morris and Ken Thompson \\nBell Laboratories \\nThis paper describes the history of the design of the \\npassword security scheme on a remotely accessed time- \\nsharing system. The present design was the result of \\ncountering observed attempts to penetrate the system. \\nThe result is a compromise between extreme security \\nand ease of use. \\nKey Words and Phrases: operating systems, \\npasswords, computer security \\nCR Categories: 2.41, 4.35 \\nIntroduction \\nPassword security on the UNIX (a trademark of Bell \\nLaboratories) time-sharing system [3] is provided by a \\ncollection of programs whose elaborate and strange de- \\nsign is the outgrowth of many years of experience with \\nearlier versions. To help develop a secure system, we \\nhave had a continuing competition to devise new ways \\nto attack the security of the system (the bad guy) and, at \\nthe same time, to devise new techniques to resist the new \\nattacks (the good guy). This competition has been in the \\nsame vein as the competition of long standing between \\nmanufacturers of armor plate and those of armor-pierc- \\ning shells. For this reason, the description that follows \\nwill trace the history of the password system rather than \\nsimply presenting the program in its current state. In this \\nway, the reasons for the design will be made clearer, as \\nthe design cannot be understood without also under- \\nstanding the potential attacks. \\nPermission to copy without fee all or part of this material is \\ngranted provided that the copies are not made or distributed for direct \\ncommercial advantage, the ACM copyright notice and the title of the \\npublication and its date appear, and notice is given that copying is by \\npermission of the Association for Computing Machinery. To copy \\notherwise, or to republish, requires a fee and/or specific permission. \\nAuthors\\' present address: R. Morris and K. Thompson, Bell Lab- \\noratories, 600 Mountain Avenue, Murray Hill, NJ 07974. \\n© 1979 ACM 0001-0782/79/1100-0594 $00.75. \\n594 An underlying goal has been to provide password \\nsecurity at minimal inconvenience to the users of the \\nsystem. For example, those who want to run a completely \\nopen system without passwords, or to have passwords \\nonly at the option of the individual users, are able to do \\nso, while those who require all of their users to have \\npasswords gain a high degree of security against penetra- \\ntion of the system by unauthorized users. \\nThe password system must be able not only to pre- \\nvent any access to the system by unauthorized users (i.e., \\nprevent them from logging in at all), but it must also \\nprevent users who are already logged in from doing \\nthings that they are not authorized to do. The so-called \\n\"super-user\" password on the UNIX system, for exam- \\nple, is especially critical because the super-user has all \\nsorts of permissions and has essentially unlimited access \\nto all system resources. \\nPassword security is of course only one component \\nof overall System security, but it is an essential compo- \\nnent. Experience has shown that attempts to penetrate \\nremote-access systems have been astonishingly sophisti- \\ncated. \\nRemote-access systems are peculiarly vulnerable to \\npenetration by outsiders as there are threats at the remote \\nterminal, along the communications link, as well as at \\nthe computer itself. Although the security of a password \\nencryption algorithm is an interesting intellectual and \\nmathematical problem, it is only one tiny facet of a very \\nlarge problem. In practice, physical security of the com- \\nputer, communications security of the communications \\nlink, and physical control of the computer itself loom as \\nfar more important issues. Perhaps most important of all \\nis control over the actions of ex-employees, since they \\nare not under any direct control and they may have \\nintimate knowledge about the system, its resources, and \\nmethods of access. Good system security involves real-are not under any direct control and they may have \\nintimate knowledge about the system, its resources, and \\nmethods of access. Good system security involves real- \\nistic evaluation of the risks not only of deliberate attacks \\nbut also of casual authorized access and accidental dis- \\nclosure. \\nPrologue \\nThe UNIX system was first implemented with a \\npassword file that contained the actual passwords of all \\nthe users, and for that reason the password file had to be \\nheavily protected against being either read or written. \\nAlthough historically, this had been the technique used \\nfor remote-access systems, it was completely unsatisfac- \\ntory for several reasons. \\nThe technique is excessively vulnerable to lapses in \\nsecurity. Temporary loss of protection can occur when \\nthe password file is being edited or otherwise modified. \\nThere is no way to prevent the making of copies by \\nprivileged users. Experience with several earlier remote- \\naccess systems showed that such lapses occur with \\nfrightening frequency. Perhaps the most memorable such \\noccasion occurred in the early 60s at a time when one of \\nCommunications November 1979 \\nof Volume 22 \\nthe ACM Number 11the authors (Morris) happened to be using the system. A \\nsystem administrator on the CTSS system at MIT was \\nediting the password file and another system administra- \\ntor was editing the daily message that is printed on \\neveryone\\'s terminal on login. Due to a software design \\nerror, the temporary editor files of the two users were \\ninterchanged and thus, for a time, the password file was \\nprinted on every terminal when it was logged in. \\nOnce such a lapse in security has been discovered, \\neveryone\\'s password must be changed, usually simulta- \\nneously, at a considerable administrative cost. This is not \\na great matter, but far more serious is the high probability \\nof such lapses going unnoticed by the system administra- \\ntors. \\nSecurity against unauthorized disclosure of the pass- \\nwords was, in the last analysis, impossible with this \\nsystem because, for example, if the contents of the file \\nsystem are put on to magnetic tape for backup, as they \\nmust be, then anyone who has physical access to the tape \\ncan read anything on it with no restriction. \\nMany programs must get information of various \\nkinds about the users of the system, and these programs \\nin general should have no special permission to read the \\npassword file. The information which should have been \\nin the password file actually was distributed (or repli- \\ncated) into a number of files, all of which had to be \\nupdated whenever a user was added to or dropped from \\nthe system. \\nThe First Scheme \\nThe obvious solution is to arrange that the passwords \\nnot appear in the system at all, and it is not difficult to \\ndecide that this can be done by encrypting each user\\'s \\npassword, putting only the encrypted form in the pass- \\nword file, and throwing away his original password (the \\none that he typed in). When the user later tries to log in \\nto the system, the password that he types is encrypted \\nand compared with the encrypted version in the pass- \\nword file. If the two match, his login attempt is accepted. \\nSuch a scheme was first described in [4, p. 91ff.]. It also \\nseemed advisable to devise a system in which neither the \\npassword file nor the password program itself needed to \\nbe protected against being read by anyone. \\nAll that was needed to implement these ideas was to \\nfind a means of encryption that was very difficult to \\ninvert, even when the encryption program is available. \\nMost of the standard encryption methods used (in the \\npast) for encryption of messages are rather easy to invert. \\nA convenient and rather good encryption program hap- \\npened to exist on the system at the time; it simulated the \\nM-209 cipher machine [1] used by the U.S. Army during \\nWorld War II. It turned out that the M-209 program was \\nusable, but with a given key, the ciphers produced by \\nthis program are trivial to invert. It is a much more \\ndifficult matter to find out the key given the cleartext \\ninput and the enciphered output of the program. There- \\n595 fore, the password was used not as the text to be en- \\ncrypted but as the key, and a constant was encrypted \\nusing this key. The encrypted result was entered into the \\npassword file. \\nAttacks on the First Approach \\nSuppose that the bad guy has available the text of \\nthe password encryption program and the complete pass- \\nword file. Suppose also that he has substantial computing \\ncapacity at his disposal. \\nOne obvious approach to penetrating the password \\nmechanism is to attempt to find a general method of \\ninverting the encryption algorithm. Very possibly this \\ncan be done, but few successful results have come to \\nlight, despite substantial efforts extending over a period \\nof more than five years. The results have not proved to \\nbe very useful in penetrating systems. \\nAnother approach to penetration is simply to keep \\ntrying potential passwords until one succeeds; this is a \\ngeneral cryptanalytic approach called key search. Human \\nbeings being what they are, there is a strong tendencytrying potential passwords until one succeeds; this is a \\ngeneral cryptanalytic approach called key search. Human \\nbeings being what they are, there is a strong tendency \\nfor people to choose relatively short and simple pass- \\nwords that they can remember. Given free choice, most \\npeople will choose their passwords from a restricted \\ncharacter set (e.g., all lower-case letters), and will often \\nchoose words or names. This human habit makes the \\nkey search job a great deal easier. \\nThe critical factor involved in key search is the \\namount of time needed to encrypt a potential password \\nand to check the result against an entry in the password \\nfile. The running time to encrypt one trial password and \\ncheck the result turned out to be approximately 1.25 \\nmilliseconds on a PDP-11/70 when the encryption al- \\ngorithm was recoded for maximum speed. It takes essen- \\ntially no more time to test the encrypted trial password \\nagainst all the passwords in an entire password file, or \\nfor that matter, against any collection of encrypted pass- \\nwords, perhaps collected from many installations. \\nIf we want to check all passwords of length n that \\nconsist entirely of lower-case letters, the number of such \\npasswords is 26 n. If we suppose that the password consists \\nof printable characters only, then the number of possible \\npasswords is somewhat less than 95 n. (The standard \\nsystem \"character erase\" and \"line kill\" characters are, \\nfor example, not prime candidates.) We can immediately \\nestimate the running time of a program that will test \\nevery password of a given length with all of its characters \\nchosen from some set of characters. The following table \\ngives estimates of the running time required on a PDP- \\n11/70 to test all possible character strings of length n \\nchosen from various sets of characters: namely, all lower- \\ncase letters, all lower-case letters plus digits, all alpha- \\nnumeric characters, all 95 printable ASCII characters, \\nand finally all 128 ASCII characters. \\nCommunications November 1979 \\nof Volume 22 \\nthe ACM Number 1136 62 \\n26 lower-case alpha- 95 all 128 \\nlower-case letters numeric printable ASCII \\nn letters and digits characters characters characters \\n1 30 msec. 40 msec. 80 msec. 120 msec. 160 msec. \\n2 800 msec. 2 sec. 5 sec, 11 sec. 20 sec. \\n3 22 sec. 58 sec. 5 min. 17 min. 44 min. \\n4 10 min. 35 min. 5 hrs. 28 hrs. 93 hrs. \\n5 4 hrs. 21 hrs. 318 hrs. 112 days 500 days \\n6 107 hrs. 760 hrs. 2.2 yrs. 29 yrs. 174 yrs. \\nOne has to conclude that it is no great matter for someone \\nwith access to a PDP-11 to test all lower-case alphabetic \\nstrings up to length five and, given access to the machine \\nfor, say, several weekends, to test all such strings up to \\nsix characters in length. By using such a program against \\na collection of actual encrypted passwords, a substantial \\nfraction of all the passwords will be found. \\nAnother profitable approach for the bad guy is to use \\nthe word list from a d!ctionary or to use a list of names. \\nFor example, a large commercial dictionary contains \\ntypically about 250,000 words; these words can be \\nchecked in about five minutes. Again, a noticeable frac- \\ntion of any collection of passwords will be found. Im- \\nprovements and extensions will be (and have been) found \\nby a determined bad guy. Some \"good\" things to try \\nare: \\n--The dictionary with the words spelled backwards. \\n--A list of first names (best obtained from some \\nmailing list). Last names, street names, and city \\nnames also work well. \\n--The above with initial upper-case letters. \\n--All valid license plate numbers in your state. (This \\ntakes about five hours in New Jersey.) \\n--Room numbers, social security numbers, telephone \\nnumbers, and the like. \\nThe authors have conducted experiments to try to \\ndetermine typical users\\' habits in the choice of passwords \\nwhen no constraint is put on their choice. The results \\nwere disappointing, except to the bad guy. In a collection \\nof 3,289 passwords gathered from many users over a \\nlong period of time, \\n15 were a single ASCII character; \\n72 were strings of two ASCII characters; \\n464 were strings of three ASCII characters; \\n477 were strings of four alphamerics; \\n706 were five letters, all upper-case or all lower-case; \\n605 were six letters, all lower-case. \\nAn additional 492 passwords appeared in various avail- \\nable dictionaries, name lists, and the like. A total of 2,831 \\nor 86 percent of this sample of passwords fell into one of \\nthese classes. \\nThere was, of course, considerable overlap between \\nthe dictionary results and the character string searches. \\nThe dictionary search alone, which required only five \\nminutes to run, produced about one third of the pass- \\nwords. \\nUsers could be urged (or forced) to use either longer passwords or passwords chosen from a larger character \\nset, or the system could itself choose passwords for the \\nusers. \\nAn Anecdote \\nAn entertaining and instructive example is the at- \\ntempt made at one installation to force users to use less \\npredictable passwords. The users did not choose their \\nown passwords; the system supplied them. The supplied \\npasswords were eight characters long and were taken \\nfrom the character set consisting of lower-case letters and \\ndigits. They were generated by a pseudorandom number \\ngenerator with only 21~ starting values. The time required \\nto search (again on a PDP-11/70) through all character \\nstrings of length 8 from a 36-character alphabet is 112 \\nyears. \\nUnfortunately, only 21~ of them need be looked at, \\nbecause that is the number of possible outputs of the \\nrandom number generator. The bad guy did, in fact, \\ngenerate and test each of these strings and found every \\none of the system-generated passwords using a total of \\nonly about one minute of machine time. In this case, no \\nharm was done, as the bad guy happened to be a friendly \\nuser. \\nImprovements to the First Approach \\n1. Slower Encryption \\nObviously, the first algorithm used was far too fast. \\nThe announcement of the DES encryption algorithm [2]user. \\nImprovements to the First Approach \\n1. Slower Encryption \\nObviously, the first algorithm used was far too fast. \\nThe announcement of the DES encryption algorithm [2] \\nby the National Bureau of Standards was timely and \\nfortunate. The DES is, by design, hard to invert, but \\nequally valuable is the fact that it is extremely slow when \\nimplemented in software. The DES was implemented \\nand used in the following way: The first eight characters \\nof the user\\'s password are used as a key for the DES; \\nthen the algorithm is used to encrypt a constant. Al- \\nthough this constant is zero at the moment, it is easily \\naccessible and can be made installation-dependent. Then \\nthe DES algorithm is iterated 25 times and the resulting \\n64 bits are repacked to become a string of 11 printable \\ncharacters. \\n2. Less Predictable Passwords \\nThe password entry program was modified so as to \\nurge the user to use more obscure passwords. If the user \\nenters an alphabetic password (all upper-case or all \\nlower-case) shorter than six characters, or a password \\nfrom a larger character set shorter than five characters, \\nthen the program asks him to enter a longer password. \\nThis further reduces the efficacy of key search. \\nThese improvements make it exceedingly difficult to \\nfind any individual password. The user is warned of the \\nrisks and if he cooperates, he is very safe indeed. On the \\nother hand, he is not prevented from using his spouse\\'s \\nname if he wants to. \\n596 Communications November 1979 \\nof Volume 22 \\nthe ACM Number 113. Salted Passwords \\nThe key search technique is still likely to turn up a \\nfew passwords when it is used on a large collection of \\npasswords, and it seemed wise to make this task as \\ndifficult as possible. To this end, when a password is first \\nentered, the password program obtains a 12-bit random \\nnumber (by reading the real-time clock) and appends \\nthis to the password typed in by the user. The concate- \\nnated string is encrypted and both the 12-bit random \\nquantity (called the salt) and the 64-bit result of the \\nencryption are entered into the password file. \\nWhen the user later logs in to the system, the 12-bit \\nquantity is extracted from the password file and ap- \\npended to the typed password. The encrypted result is \\nrequired, as before, to be the same as the remaining 64 \\nbits in the password file. This modification does not \\nincrease the task of finding any individual password, \\nstarting from scratch, but now the work of testing a given \\ncharacter string against a large collection of encrypted \\npasswords has been multiplied by 4,096 (212). The reason \\nfor this is that there are 4,096 encrypted versions of each \\npassword and one of them has been picked more or less \\nat random by the system. \\nWith this modification, it is likely that the bad guy \\ncan spend days of computer time trying to find a pass- \\nword on a system with hundreds of passwords, and find \\nnone at all. More important is the fact that it becomes \\nimpractical to prepare an encrypted dictionary in ad- \\nvance. Such an encrypted dictionary could be used to \\ncrack new passwords in milliseconds when they appear. \\nThere is a (not inadvertent) side effect of this modi- \\nfication. It becomes nearly impossible to find out whether \\na person with passwords on two or more systems has \\nused the same password on all of them, unless you \\nalready know that. \\n4. The Threat of the DES Chip \\nChips to perform the DES encryption are already \\ncommercially available and they are very fast. The use \\nof such a chip speeds up the process of password hunting \\nby three orders of magnitude. To avert this possibility, \\none of the internal tables of the DES algorithm (in \\nparticular, the so-called E-table) is changed in a way that \\ndepends on the 12-bit random number. The E-table is \\ninseparably wired into the DES chip, so that the com- \\nmercial chip cannot be used. Obviously, the bad guy \\ncould have his own chip designed and built, but the cost \\nwould be very high. \\n5. A Subtle Point \\nTo log in successfully on the UNIX system, it is \\nnecessary after dialing in to type a valid user name, and \\nthen the correct password for that user name. It is poor \\ndesign to write the login command in such a way that it \\ntells an interloper when he has typed in an invalid user \\nname. The response to an invalid name should be iden- \\ntical to that for a valid name. \\nWhen the slow encryption algorithm was first imple- \\n597 mented, the encryption was done only if the user name \\nwas valid, because otherwise there was no encrypted \\npassword to compare with the supplied password. The \\nresult was that the response was delayed by about one- \\nhalf second if the name was valid, but was immediate if \\ninvalid. The bad guy could find out whether a particular \\nuser name was valid. The routine was modified to do the \\nencryption in either case. \\nConclusions \\nOn the issue of password security, UNIX is probably \\nbetter than most systems. The use of encrypted pass- \\nwords appears reasonably secure in the absence of seri- \\nous attention of experts in the field. \\nIt is also worth some effort to conceal even the \\nencrypted passwords. Some UNIX systems have insti- \\ntuted what is called an \"external security code\" that must \\nbe typed when dialing into the system, but before logging \\nin. If this code is changed periodically, then someone \\nwith an old password will likely be prevented from using \\nit. \\nWhenever any security procedure is set up to deny \\naccess to unauthorized persons, it is wise to keep a recordwith an old password will likely be prevented from using \\nit. \\nWhenever any security procedure is set up to deny \\naccess to unauthorized persons, it is wise to keep a record \\nof both successful and unsuccessful attempts to get at the \\nsecured resource. For example, an out-of-hours visitor to \\na computer center normally must not only identify him- \\nself, but a record is usually also kept of his entry. Just so, \\nit is a wise precaution to make and keep a record of all \\nattempts to log into a remote-access time-sharing system, \\nand certainly all unsuccessful attempts. \\nBad guys fall on a spectrum whose one end is some- \\none with ordinary access to a system and whose goal is \\nto find out a particular password (usually that of the \\nsuper-user) and, at the other end, someone who wishes \\nto collect as much password information as possible from \\nas many systems as possible. Most of the work reported \\nhere serves to frustrate the latter type; our experience \\nindicates that the former type of bad guy never Was very \\nsuccessful. \\nWe recognize that a time-sharing system must oper- \\nate in a hostile environment. We did not attempt to hide \\nthe security aspects of the operating system, thereby \\nplaying the customary make-believe game in which \\nweaknesses of the system are not discussed no matter \\nhow apparent. Rather we advertised the password algo- \\nrithm and invited attack in the belief that this approach \\nwould minimize future trouble. The approach has been \\nsuccessful. \\nReceived August 1978; revised August 1979 \\nReferences \\ni. Hagelin, B. Ciphering Machine (M-209), U.S. Patent No. \\n2,089,603, Aug. 10, 1937. \\n2. Proposed federal information processing data encryption \\nstandard. Federal Register (40FR12134), March 17, 1975. \\n3. Ritchie, D.M., and Thompson, K. The UNIX time-sharing \\nsystem. Comm. ACM 17, 7 (July 1974), 365-375. \\n4. Wilkes, M.V. Time-Sharing Computer Systems. American \\nElsevier, New York, 1968. \\nCommunications November 1979 \\nof Volume 22 \\nthe ACM Number 11'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "2ab4eb4819d6466abef85b9be0c29497",
            "aac560be7b3e4582a8554b6bf0452dc1",
            "dc724b49fa8247fba6e2d8d2fc98f13f",
            "faad74d825f346d38bb83cdebf05719a",
            "11a8470b5aef4255b0ab71f6d8f9acba",
            "861733038fd94d028a43bba0b335b7ad",
            "1b758ef90b8b4bd88b4a9ad928a7d1c5",
            "2fc257e4a2a54dd49f129b44428bd5f7",
            "34ffd9f3df0a433dbbb22bc497bc8b76",
            "f91e9e7ef2564f5b928cdc201a0a0172",
            "29d2ed3f3f254264865c83e0378d5cfd",
            "7b009fce674d4675901088c10fd036af",
            "66144d0b62f244cba8b3c5f9255733ba",
            "97556ec181d542af980fb30cc1a66cb4",
            "87e318d8871b456889686cbd0752656c",
            "038dcf017015418d89c41f220e87f978",
            "5078c75c25c747c880ce6b3e16a41c74",
            "38a99ade60c84f8bb785c0fcd04feded",
            "a1a17506eaa04fd596f9f8c08d5c52b0",
            "35b7a43577bd4540b5ba5534105bf3f8",
            "b1050fa2a2b641e7bcecb53f584a283c",
            "cd29fc5f99e14130ab64bdfedf117a1e",
            "31059df6003d49f1994f87c409e5f19f",
            "5e1acb074d1f47d38335c1684ae7e337",
            "b904bc84290547c98aadf2c2ed3d4773",
            "69c9ac87c0f84ff194ee78b3e8aebaa9",
            "c0915161597a4e1180800e7229d01440",
            "75ac986a1d0a4266a26ef914640f7e50",
            "0344fe41cee24a13b773902315f236d8",
            "d36bd834b8bd4db492ba4074ed4459b6",
            "af28a4eab1c0489ebc2ab6f519230fdc",
            "341fb06bf89c47928b5c14ec9710a1fd",
            "65b61104c20b4633a6d975e98e306d2a",
            "03e117ecec6e4bbab262a559f0d3c98f",
            "eb0e9eba827444d7be2693250ad34298",
            "de4ec3674a55449abfb8e3fb09f2e9ae",
            "b1b14448a0604c3598650f118b65a5ed",
            "08645085b2614e79b19e150f628a237f",
            "fcd78d00546f4b86b9ba6ef523432469",
            "734785855dc341a99681c4b238265c99",
            "035679c60eab45518a8017f0c1ede4c5",
            "fa9f9a39081d4700ae4f0e4e91d9b4bc",
            "33576d4c08034d6e8a717dd4f9ed3ae2",
            "f4b7760a74b94b2c811aedead8506de8",
            "cfe7e8f8d33e419ebae4ce877f2cde2b",
            "7ccb5a9689d84d1da4779f88c5e51e6c",
            "8c2f6d986ad247a297ba215f4c2e4c62",
            "1397cf2b626547bc9a3be1e203c8b17c",
            "129c385dadd14e3294046b03863a1b1b",
            "4404a9b43c994d40aea040c10e73a842",
            "90464ecea2e64826973167ea63478614",
            "556dee3bc11540849436b0ac3a70b8e1",
            "5a59fa2fa767468bab1acb6a2894132e",
            "5b09a2405a5347068af1c38a46778cfb",
            "174bfa6897b14a749e97a623d48057d8",
            "a4754bdf3fb049bf8dd3c8228d75e536",
            "30ab57c8850f42afa5f574b3a4c9fe49",
            "a3b6f5dbf7664734ba617094b8a087f2",
            "b56fdd0d006b47a8952c635ca958b40e",
            "5d4afa99f123446084fb8be33161373c",
            "8a6e0f6cf22246ab8813ed6d02d341ac",
            "588b5b11216a42bfab6443edb4a8cd91",
            "34fa27c0b79a4fdba60329822c59a2a3",
            "d366b9cf8d3f4cd6b5d905286e27452a",
            "737bcae6205640e191e6c3921d3b0473",
            "c44f952f5c06453fa19a6b57c2859134",
            "558d2c121aae4d6fbf5e8d8a5835a4d1",
            "2a3df9385f7d49c193c1e3c0183a4265",
            "a77c1437cf16482fac6aa75efe5fdd2c",
            "c77e7c6406ea488e93d469ef585a7aca",
            "d6f7195b32784f32ae57357e913e8aad",
            "4d0885a1220c48359fb93a5fc29a5504",
            "f3c06bcee13c44d2a0af7376f2fb31d5",
            "191b2d29f22743a4b8e5d59195ec1b20",
            "6117a92e103940d5b8f90be2477d4742",
            "48c7b82a18c74025b4c911528b2d37e2",
            "ce5134cff7994da78a0c0cffd1d29c22",
            "db71c65008fc45e3949aaf4f97bc4254",
            "85b12d74dad743d8abdac2165deac1de",
            "04495a348177422697e93bb76f74b812",
            "4593b4a027f6403f88a4e41a10aadaab",
            "436c1f7bd50147a49024ac45016abb6f",
            "fa52c54ae3294e5fbd5c9aa0c4d7cd3d",
            "2e579551ce7a47818aef65ff967fed7a",
            "c5d9450b9fad4e2cb41a36f5a0e694ad",
            "597f8b78c85145dd97fe8992a3071339",
            "3d69f636652c47b1bfd7556be8dc784c",
            "110a662f4ed3421684eda6bbcbbb66a4",
            "c917820573034b81a2e56e3ea894d04a",
            "43d449f57673405cbbb1a27939b83765",
            "59a8e9328e154d7f9afe8ed8f9e7f052",
            "e9df0633bb0642c991aaa922dacd9893",
            "a84148ab152b4b41a4856597ae5e1b0a",
            "b35a09d139c04d368df55e1371a6723a",
            "d839daec254640ecad1ed4235ca41ada",
            "9d500b92ddd148ca8a23e4bcf897bd35",
            "1ab65ff142d64b978c5fd10f1f609551",
            "aced207484d44131997e1ce78cbab875",
            "0295d844fab743a7b0d0a88aa920a902",
            "ec12ae25a07442fc8b873bca5e4195f0",
            "4523b10103be4bbfbb7147948f54fe4c",
            "e118f127ca1240e68cdf875fc415cc73",
            "0b7f941ca3084abf84ee906128469046",
            "75704a673ec74f788dc52017a31c9ce3",
            "e3cbd82a48034e49ab40d829c74424f9",
            "a90caf68425c47ae9bcbb074e9e565a1",
            "2aae6f6041ea4781b62ff5d5ce77dbea",
            "c711ee9e7a5a4a848b2a439a208219f3",
            "aca333595d40413fa6c7a6b0f2e6fed8",
            "1f1b6da1c6e842d3ac43a49c794c7c54",
            "fa3744a5458e405a919e25885c06227b",
            "2fc8a1a785c4432ebe7ad9cf9f4758ee",
            "c2c3db6fc2714a868f90c38a6ccb42bf",
            "95af06fb80024ab08fcf85c1f4ca198c",
            "567c9237e6b44be6b2e859cbc5885d3f",
            "a1c93076dd514aa6b9a0c1fc7b5cc796",
            "b954cee3b2cd454baa4cce5f06561c77",
            "4d319f0e8c634c83b415e7e2de2ac4f3",
            "7d79c15b979040cbb4161098c3f92c56",
            "34f9ccd1098046d5aff66b2a2f1f34ec",
            "1384721dca3446639aac794daebd7a9c"
          ]
        },
        "id": "u8qPWoPOK0zf",
        "outputId": "e3e31291-5d1e-4d88-d6d1-6c94cee552a3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab4eb4819d6466abef85b9be0c29497"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b009fce674d4675901088c10fd036af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/113k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31059df6003d49f1994f87c409e5f19f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03e117ecec6e4bbab262a559f0d3c98f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfe7e8f8d33e419ebae4ce877f2cde2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/670M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4754bdf3fb049bf8dd3c8228d75e536"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "558d2c121aae4d6fbf5e8d8a5835a4d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db71c65008fc45e3949aaf4f97bc4254"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c917820573034b81a2e56e3ea894d04a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec12ae25a07442fc8b873bca5e4195f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa3744a5458e405a919e25885c06227b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "# 1. Specify preffered dimensions\n",
        "dimensions = 1024\n",
        "\n",
        "# 2. load model\n",
        "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dimensions)\n",
        "\n",
        "# Define the embedding function using a pre-trained model\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")\n",
        "\n",
        "\n",
        "text_splitter = SemanticChunker(embedding_function, breakpoint_threshold_amount=50)\n",
        "# from langchain_text_splitters import TokenTextSplitter\n",
        "\n",
        "# text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
        "\n",
        "texts = text_splitter.split_text(text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5hZV5iPOvdG",
        "outputId": "49d2b98b-35e8-4377-9f34-18d104940e27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Operating R. Stockton Gaines \\nSystems Editor \\nPassword Security: \\nA Case History \\nRobert Morris and Ken Thompson \\nBell Laboratories \\nThis paper describes the history of the design of the \\npassword security scheme on a remotely accessed time- \\nsharing system. The present design was the result of \\ncountering observed attempts to penetrate the system.',\n",
              " 'The result is a compromise between extreme security \\nand ease of use. Key Words and Phrases: operating systems, \\npasswords, computer security \\nCR Categories: 2.41, 4.35 \\nIntroduction \\nPassword security on the UNIX (a trademark of Bell \\nLaboratories) time-sharing system [3] is provided by a \\ncollection of programs whose elaborate and strange de- \\nsign is the outgrowth of many years of experience with \\nearlier versions. To help develop a secure system, we \\nhave had a continuing competition to devise new ways \\nto attack the security of the system (the bad guy) and, at \\nthe same time, to devise new techniques to resist the new \\nattacks (the good guy).',\n",
              " 'This competition has been in the \\nsame vein as the competition of long standing between \\nmanufacturers of armor plate and those of armor-pierc- \\ning shells. For this reason, the description that follows \\nwill trace the history of the password system rather than \\nsimply presenting the program in its current state.',\n",
              " 'In this \\nway, the reasons for the design will be made clearer, as \\nthe design cannot be understood without also under- \\nstanding the potential attacks. Permission to copy without fee all or part of this material is \\ngranted provided that the copies are not made or distributed for direct \\ncommercial advantage, the ACM copyright notice and the title of the \\npublication and its date appear, and notice is given that copying is by \\npermission of the Association for Computing Machinery. To copy \\notherwise, or to republish, requires a fee and/or specific permission.',\n",
              " \"Authors' present address: R.\",\n",
              " 'Morris and K.',\n",
              " 'Thompson, Bell Lab- \\noratories, 600 Mountain Avenue, Murray Hill, NJ 07974.',\n",
              " '© 1979 ACM 0001-0782/79/1100-0594 $00.75.',\n",
              " '594 An underlying goal has been to provide password \\nsecurity at minimal inconvenience to the users of the \\nsystem. For example, those who want to run a completely \\nopen system without passwords, or to have passwords \\nonly at the option of the individual users, are able to do \\nso, while those who require all of their users to have \\npasswords gain a high degree of security against penetra- \\ntion of the system by unauthorized users.',\n",
              " 'The password system must be able not only to pre- \\nvent any access to the system by unauthorized users (i.e., \\nprevent them from logging in at all), but it must also \\nprevent users who are already logged in from doing \\nthings that they are not authorized to do. The so-called \\n\"super-user\" password on the UNIX system, for exam- \\nple, is especially critical because the super-user has all \\nsorts of permissions and has essentially unlimited access \\nto all system resources. Password security is of course only one component \\nof overall System security, but it is an essential compo- \\nnent.',\n",
              " 'Experience has shown that attempts to penetrate \\nremote-access systems have been astonishingly sophisti- \\ncated. Remote-access systems are peculiarly vulnerable to \\npenetration by outsiders as there are threats at the remote \\nterminal, along the communications link, as well as at \\nthe computer itself. Although the security of a password \\nencryption algorithm is an interesting intellectual and \\nmathematical problem, it is only one tiny facet of a very \\nlarge problem. In practice, physical security of the com- \\nputer, communications security of the communications \\nlink, and physical control of the computer itself loom as \\nfar more important issues.',\n",
              " 'Perhaps most important of all \\nis control over the actions of ex-employees, since they \\nare not under any direct control and they may have \\nintimate knowledge about the system, its resources, and \\nmethods of access. Good system security involves real-are not under any direct control and they may have \\nintimate knowledge about the system, its resources, and \\nmethods of access.',\n",
              " 'Good system security involves real- \\nistic evaluation of the risks not only of deliberate attacks \\nbut also of casual authorized access and accidental dis- \\nclosure. Prologue \\nThe UNIX system was first implemented with a \\npassword file that contained the actual passwords of all \\nthe users, and for that reason the password file had to be \\nheavily protected against being either read or written. Although historically, this had been the technique used \\nfor remote-access systems, it was completely unsatisfac- \\ntory for several reasons.',\n",
              " 'The technique is excessively vulnerable to lapses in \\nsecurity.',\n",
              " 'Temporary loss of protection can occur when \\nthe password file is being edited or otherwise modified. There is no way to prevent the making of copies by \\nprivileged users.',\n",
              " 'Experience with several earlier remote- \\naccess systems showed that such lapses occur with \\nfrightening frequency.',\n",
              " 'Perhaps the most memorable such \\noccasion occurred in the early 60s at a time when one of \\nCommunications November 1979 \\nof Volume 22 \\nthe ACM Number 11the authors (Morris) happened to be using the system.',\n",
              " \"A \\nsystem administrator on the CTSS system at MIT was \\nediting the password file and another system administra- \\ntor was editing the daily message that is printed on \\neveryone's terminal on login. Due to a software design \\nerror, the temporary editor files of the two users were \\ninterchanged and thus, for a time, the password file was \\nprinted on every terminal when it was logged in. Once such a lapse in security has been discovered, \\neveryone's password must be changed, usually simulta- \\nneously, at a considerable administrative cost.\",\n",
              " \"This is not \\na great matter, but far more serious is the high probability \\nof such lapses going unnoticed by the system administra- \\ntors. Security against unauthorized disclosure of the pass- \\nwords was, in the last analysis, impossible with this \\nsystem because, for example, if the contents of the file \\nsystem are put on to magnetic tape for backup, as they \\nmust be, then anyone who has physical access to the tape \\ncan read anything on it with no restriction. Many programs must get information of various \\nkinds about the users of the system, and these programs \\nin general should have no special permission to read the \\npassword file. The information which should have been \\nin the password file actually was distributed (or repli- \\ncated) into a number of files, all of which had to be \\nupdated whenever a user was added to or dropped from \\nthe system. The First Scheme \\nThe obvious solution is to arrange that the passwords \\nnot appear in the system at all, and it is not difficult to \\ndecide that this can be done by encrypting each user's \\npassword, putting only the encrypted form in the pass- \\nword file, and throwing away his original password (the \\none that he typed in). When the user later tries to log in \\nto the system, the password that he types is encrypted \\nand compared with the encrypted version in the pass- \\nword file.\",\n",
              " 'If the two match, his login attempt is accepted.',\n",
              " 'Such a scheme was first described in [4, p.',\n",
              " '91ff.].',\n",
              " 'It also \\nseemed advisable to devise a system in which neither the \\npassword file nor the password program itself needed to \\nbe protected against being read by anyone. All that was needed to implement these ideas was to \\nfind a means of encryption that was very difficult to \\ninvert, even when the encryption program is available.',\n",
              " 'Most of the standard encryption methods used (in the \\npast) for encryption of messages are rather easy to invert. A convenient and rather good encryption program hap- \\npened to exist on the system at the time; it simulated the \\nM-209 cipher machine [1] used by the U.S. Army during \\nWorld War II. It turned out that the M-209 program was \\nusable, but with a given key, the ciphers produced by \\nthis program are trivial to invert. It is a much more \\ndifficult matter to find out the key given the cleartext \\ninput and the enciphered output of the program. There- \\n595 fore, the password was used not as the text to be en- \\ncrypted but as the key, and a constant was encrypted \\nusing this key. The encrypted result was entered into the \\npassword file. Attacks on the First Approach \\nSuppose that the bad guy has available the text of \\nthe password encryption program and the complete pass- \\nword file.',\n",
              " 'Suppose also that he has substantial computing \\ncapacity at his disposal. One obvious approach to penetrating the password \\nmechanism is to attempt to find a general method of \\ninverting the encryption algorithm. Very possibly this \\ncan be done, but few successful results have come to \\nlight, despite substantial efforts extending over a period \\nof more than five years.',\n",
              " 'The results have not proved to \\nbe very useful in penetrating systems. Another approach to penetration is simply to keep \\ntrying potential passwords until one succeeds; this is a \\ngeneral cryptanalytic approach called key search. Human \\nbeings being what they are, there is a strong tendencytrying potential passwords until one succeeds; this is a \\ngeneral cryptanalytic approach called key search.',\n",
              " 'Human \\nbeings being what they are, there is a strong tendency \\nfor people to choose relatively short and simple pass- \\nwords that they can remember. Given free choice, most \\npeople will choose their passwords from a restricted \\ncharacter set (e.g., all lower-case letters), and will often \\nchoose words or names. This human habit makes the \\nkey search job a great deal easier.',\n",
              " 'The critical factor involved in key search is the \\namount of time needed to encrypt a potential password \\nand to check the result against an entry in the password \\nfile. The running time to encrypt one trial password and \\ncheck the result turned out to be approximately 1.25 \\nmilliseconds on a PDP-11/70 when the encryption al- \\ngorithm was recoded for maximum speed. It takes essen- \\ntially no more time to test the encrypted trial password \\nagainst all the passwords in an entire password file, or \\nfor that matter, against any collection of encrypted pass- \\nwords, perhaps collected from many installations. If we want to check all passwords of length n that \\nconsist entirely of lower-case letters, the number of such \\npasswords is 26 n. If we suppose that the password consists \\nof printable characters only, then the number of possible \\npasswords is somewhat less than 95 n. (The standard \\nsystem \"character erase\" and \"line kill\" characters are, \\nfor example, not prime candidates.) We can immediately \\nestimate the running time of a program that will test \\nevery password of a given length with all of its characters \\nchosen from some set of characters. The following table \\ngives estimates of the running time required on a PDP- \\n11/70 to test all possible character strings of length n \\nchosen from various sets of characters: namely, all lower- \\ncase letters, all lower-case letters plus digits, all alpha- \\nnumeric characters, all 95 printable ASCII characters, \\nand finally all 128 ASCII characters. Communications November 1979 \\nof Volume 22 \\nthe ACM Number 1136 62 \\n26 lower-case alpha- 95 all 128 \\nlower-case letters numeric printable ASCII \\nn letters and digits characters characters characters \\n1 30 msec.',\n",
              " '40 msec.',\n",
              " '80 msec. 120 msec. 160 msec.',\n",
              " '2 800 msec. 2 sec.',\n",
              " '5 sec, 11 sec. 20 sec. 3 22 sec. 58 sec.',\n",
              " '5 min. 17 min. 44 min. 4 10 min.',\n",
              " '35 min.',\n",
              " '5 hrs. 28 hrs. 93 hrs. 5 4 hrs.',\n",
              " '21 hrs.',\n",
              " '318 hrs. 112 days 500 days \\n6 107 hrs. 760 hrs.',\n",
              " '2.2 yrs.',\n",
              " '29 yrs.',\n",
              " '174 yrs.',\n",
              " 'One has to conclude that it is no great matter for someone \\nwith access to a PDP-11 to test all lower-case alphabetic \\nstrings up to length five and, given access to the machine \\nfor, say, several weekends, to test all such strings up to \\nsix characters in length. By using such a program against \\na collection of actual encrypted passwords, a substantial \\nfraction of all the passwords will be found. Another profitable approach for the bad guy is to use \\nthe word list from a d!ctionary or to use a list of names. For example, a large commercial dictionary contains \\ntypically about 250,000 words; these words can be \\nchecked in about five minutes. Again, a noticeable frac- \\ntion of any collection of passwords will be found.',\n",
              " 'Im- \\nprovements and extensions will be (and have been) found \\nby a determined bad guy.',\n",
              " 'Some \"good\" things to try \\nare: \\n--The dictionary with the words spelled backwards.',\n",
              " '--A list of first names (best obtained from some \\nmailing list).',\n",
              " 'Last names, street names, and city \\nnames also work well.',\n",
              " '--The above with initial upper-case letters.',\n",
              " '--All valid license plate numbers in your state.',\n",
              " '(This \\ntakes about five hours in New Jersey.) \\n--Room numbers, social security numbers, telephone \\nnumbers, and the like.',\n",
              " \"The authors have conducted experiments to try to \\ndetermine typical users' habits in the choice of passwords \\nwhen no constraint is put on their choice.\",\n",
              " 'The results \\nwere disappointing, except to the bad guy. In a collection \\nof 3,289 passwords gathered from many users over a \\nlong period of time, \\n15 were a single ASCII character; \\n72 were strings of two ASCII characters; \\n464 were strings of three ASCII characters; \\n477 were strings of four alphamerics; \\n706 were five letters, all upper-case or all lower-case; \\n605 were six letters, all lower-case. An additional 492 passwords appeared in various avail- \\nable dictionaries, name lists, and the like.',\n",
              " 'A total of 2,831 \\nor 86 percent of this sample of passwords fell into one of \\nthese classes. There was, of course, considerable overlap between \\nthe dictionary results and the character string searches. The dictionary search alone, which required only five \\nminutes to run, produced about one third of the pass- \\nwords. Users could be urged (or forced) to use either longer passwords or passwords chosen from a larger character \\nset, or the system could itself choose passwords for the \\nusers.',\n",
              " 'An Anecdote \\nAn entertaining and instructive example is the at- \\ntempt made at one installation to force users to use less \\npredictable passwords. The users did not choose their \\nown passwords; the system supplied them.',\n",
              " 'The supplied \\npasswords were eight characters long and were taken \\nfrom the character set consisting of lower-case letters and \\ndigits.',\n",
              " 'They were generated by a pseudorandom number \\ngenerator with only 21~ starting values.',\n",
              " 'The time required \\nto search (again on a PDP-11/70) through all character \\nstrings of length 8 from a 36-character alphabet is 112 \\nyears. Unfortunately, only 21~ of them need be looked at, \\nbecause that is the number of possible outputs of the \\nrandom number generator.',\n",
              " 'The bad guy did, in fact, \\ngenerate and test each of these strings and found every \\none of the system-generated passwords using a total of \\nonly about one minute of machine time. In this case, no \\nharm was done, as the bad guy happened to be a friendly \\nuser.',\n",
              " 'Improvements to the First Approach \\n1.',\n",
              " 'Slower Encryption \\nObviously, the first algorithm used was far too fast. The announcement of the DES encryption algorithm [2]user. Improvements to the First Approach \\n1. Slower Encryption \\nObviously, the first algorithm used was far too fast. The announcement of the DES encryption algorithm [2] \\nby the National Bureau of Standards was timely and \\nfortunate.',\n",
              " \"The DES is, by design, hard to invert, but \\nequally valuable is the fact that it is extremely slow when \\nimplemented in software. The DES was implemented \\nand used in the following way: The first eight characters \\nof the user's password are used as a key for the DES; \\nthen the algorithm is used to encrypt a constant. Al- \\nthough this constant is zero at the moment, it is easily \\naccessible and can be made installation-dependent.\",\n",
              " 'Then \\nthe DES algorithm is iterated 25 times and the resulting \\n64 bits are repacked to become a string of 11 printable \\ncharacters.',\n",
              " '2.',\n",
              " 'Less Predictable Passwords \\nThe password entry program was modified so as to \\nurge the user to use more obscure passwords. If the user \\nenters an alphabetic password (all upper-case or all \\nlower-case) shorter than six characters, or a password \\nfrom a larger character set shorter than five characters, \\nthen the program asks him to enter a longer password. This further reduces the efficacy of key search.',\n",
              " 'These improvements make it exceedingly difficult to \\nfind any individual password.',\n",
              " 'The user is warned of the \\nrisks and if he cooperates, he is very safe indeed.',\n",
              " \"On the \\nother hand, he is not prevented from using his spouse's \\nname if he wants to.\",\n",
              " '596 Communications November 1979 \\nof Volume 22 \\nthe ACM Number 113.',\n",
              " 'Salted Passwords \\nThe key search technique is still likely to turn up a \\nfew passwords when it is used on a large collection of \\npasswords, and it seemed wise to make this task as \\ndifficult as possible. To this end, when a password is first \\nentered, the password program obtains a 12-bit random \\nnumber (by reading the real-time clock) and appends \\nthis to the password typed in by the user. The concate- \\nnated string is encrypted and both the 12-bit random \\nquantity (called the salt) and the 64-bit result of the \\nencryption are entered into the password file. When the user later logs in to the system, the 12-bit \\nquantity is extracted from the password file and ap- \\npended to the typed password.',\n",
              " 'The encrypted result is \\nrequired, as before, to be the same as the remaining 64 \\nbits in the password file. This modification does not \\nincrease the task of finding any individual password, \\nstarting from scratch, but now the work of testing a given \\ncharacter string against a large collection of encrypted \\npasswords has been multiplied by 4,096 (212). The reason \\nfor this is that there are 4,096 encrypted versions of each \\npassword and one of them has been picked more or less \\nat random by the system.',\n",
              " 'With this modification, it is likely that the bad guy \\ncan spend days of computer time trying to find a pass- \\nword on a system with hundreds of passwords, and find \\nnone at all. More important is the fact that it becomes \\nimpractical to prepare an encrypted dictionary in ad- \\nvance. Such an encrypted dictionary could be used to \\ncrack new passwords in milliseconds when they appear.',\n",
              " 'There is a (not inadvertent) side effect of this modi- \\nfication.',\n",
              " 'It becomes nearly impossible to find out whether \\na person with passwords on two or more systems has \\nused the same password on all of them, unless you \\nalready know that.',\n",
              " '4.',\n",
              " 'The Threat of the DES Chip \\nChips to perform the DES encryption are already \\ncommercially available and they are very fast. The use \\nof such a chip speeds up the process of password hunting \\nby three orders of magnitude. To avert this possibility, \\none of the internal tables of the DES algorithm (in \\nparticular, the so-called E-table) is changed in a way that \\ndepends on the 12-bit random number. The E-table is \\ninseparably wired into the DES chip, so that the com- \\nmercial chip cannot be used.',\n",
              " 'Obviously, the bad guy \\ncould have his own chip designed and built, but the cost \\nwould be very high.',\n",
              " '5.',\n",
              " 'A Subtle Point \\nTo log in successfully on the UNIX system, it is \\nnecessary after dialing in to type a valid user name, and \\nthen the correct password for that user name. It is poor \\ndesign to write the login command in such a way that it \\ntells an interloper when he has typed in an invalid user \\nname.',\n",
              " 'The response to an invalid name should be iden- \\ntical to that for a valid name.',\n",
              " 'When the slow encryption algorithm was first imple- \\n597 mented, the encryption was done only if the user name \\nwas valid, because otherwise there was no encrypted \\npassword to compare with the supplied password. The \\nresult was that the response was delayed by about one- \\nhalf second if the name was valid, but was immediate if \\ninvalid. The bad guy could find out whether a particular \\nuser name was valid.',\n",
              " 'The routine was modified to do the \\nencryption in either case. Conclusions \\nOn the issue of password security, UNIX is probably \\nbetter than most systems. The use of encrypted pass- \\nwords appears reasonably secure in the absence of seri- \\nous attention of experts in the field.',\n",
              " 'It is also worth some effort to conceal even the \\nencrypted passwords. Some UNIX systems have insti- \\ntuted what is called an \"external security code\" that must \\nbe typed when dialing into the system, but before logging \\nin. If this code is changed periodically, then someone \\nwith an old password will likely be prevented from using \\nit.',\n",
              " 'Whenever any security procedure is set up to deny \\naccess to unauthorized persons, it is wise to keep a recordwith an old password will likely be prevented from using \\nit.',\n",
              " 'Whenever any security procedure is set up to deny \\naccess to unauthorized persons, it is wise to keep a record \\nof both successful and unsuccessful attempts to get at the \\nsecured resource. For example, an out-of-hours visitor to \\na computer center normally must not only identify him- \\nself, but a record is usually also kept of his entry.',\n",
              " 'Just so, \\nit is a wise precaution to make and keep a record of all \\nattempts to log into a remote-access time-sharing system, \\nand certainly all unsuccessful attempts. Bad guys fall on a spectrum whose one end is some- \\none with ordinary access to a system and whose goal is \\nto find out a particular password (usually that of the \\nsuper-user) and, at the other end, someone who wishes \\nto collect as much password information as possible from \\nas many systems as possible. Most of the work reported \\nhere serves to frustrate the latter type; our experience \\nindicates that the former type of bad guy never Was very \\nsuccessful.',\n",
              " 'We recognize that a time-sharing system must oper- \\nate in a hostile environment. We did not attempt to hide \\nthe security aspects of the operating system, thereby \\nplaying the customary make-believe game in which \\nweaknesses of the system are not discussed no matter \\nhow apparent.',\n",
              " 'Rather we advertised the password algo- \\nrithm and invited attack in the belief that this approach \\nwould minimize future trouble.',\n",
              " 'The approach has been \\nsuccessful.',\n",
              " 'Received August 1978; revised August 1979 \\nReferences \\ni.',\n",
              " 'Hagelin, B.',\n",
              " 'Ciphering Machine (M-209), U.S.',\n",
              " 'Patent No.',\n",
              " '2,089,603, Aug.',\n",
              " '10, 1937.',\n",
              " '2.',\n",
              " 'Proposed federal information processing data encryption \\nstandard. Federal Register (40FR12134), March 17, 1975.',\n",
              " '3.',\n",
              " 'Ritchie, D.M., and Thompson, K. The UNIX time-sharing \\nsystem.',\n",
              " 'Comm.',\n",
              " 'ACM 17, 7 (July 1974), 365-375.',\n",
              " '4.',\n",
              " 'Wilkes, M.V.',\n",
              " 'Time-Sharing Computer Systems.',\n",
              " 'American \\nElsevier, New York, 1968.',\n",
              " 'Communications November 1979 \\nof Volume 22 \\nthe ACM Number 11']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHQzKTNuVKsy",
        "outputId": "db4c3030-d78c-4c64-d1c9-45b118bf73fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[350,\n",
              " 655,\n",
              " 314,\n",
              " 565,\n",
              " 28,\n",
              " 13,\n",
              " 75,\n",
              " 41,\n",
              " 434,\n",
              " 589,\n",
              " 654,\n",
              " 378,\n",
              " 536,\n",
              " 63,\n",
              " 171,\n",
              " 114,\n",
              " 205,\n",
              " 541,\n",
              " 1345,\n",
              " 48,\n",
              " 43,\n",
              " 7,\n",
              " 329,\n",
              " 899,\n",
              " 371,\n",
              " 398,\n",
              " 376,\n",
              " 1723,\n",
              " 8,\n",
              " 28,\n",
              " 18,\n",
              " 40,\n",
              " 32,\n",
              " 7,\n",
              " 31,\n",
              " 7,\n",
              " 47,\n",
              " 8,\n",
              " 7,\n",
              " 8,\n",
              " 728,\n",
              " 86,\n",
              " 83,\n",
              " 64,\n",
              " 57,\n",
              " 44,\n",
              " 48,\n",
              " 121,\n",
              " 152,\n",
              " 504,\n",
              " 493,\n",
              " 219,\n",
              " 135,\n",
              " 86,\n",
              " 270,\n",
              " 259,\n",
              " 38,\n",
              " 359,\n",
              " 432,\n",
              " 132,\n",
              " 2,\n",
              " 407,\n",
              " 82,\n",
              " 78,\n",
              " 85,\n",
              " 67,\n",
              " 704,\n",
              " 508,\n",
              " 385,\n",
              " 65,\n",
              " 171,\n",
              " 2,\n",
              " 499,\n",
              " 101,\n",
              " 2,\n",
              " 303,\n",
              " 80,\n",
              " 409,\n",
              " 278,\n",
              " 338,\n",
              " 171,\n",
              " 340,\n",
              " 628,\n",
              " 282,\n",
              " 130,\n",
              " 34,\n",
              " 57,\n",
              " 11,\n",
              " 31,\n",
              " 10,\n",
              " 15,\n",
              " 9,\n",
              " 2,\n",
              " 112,\n",
              " 2,\n",
              " 62,\n",
              " 5,\n",
              " 31,\n",
              " 2,\n",
              " 12,\n",
              " 30,\n",
              " 35,\n",
              " 61]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "print(len(texts))\n",
        "[len(x) for x in texts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ltT7KfuW2d"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiFG8gdMpngX",
        "outputId": "b42d715f-72da-4027-d963-37b763cfc05c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "655 --> [69, 351, 233]\n",
            "565 --> [151, 333, 79]\n",
            "589 --> [261, 328]\n",
            "536 --> [396, 140]\n",
            "541 --> [387, 345]\n",
            "899 --> [297, 316, 396, 346]\n",
            "1723 --> [368, 242, 378, 171, 350, 210]\n",
            "728 --> [264, 387, 213]\n",
            "704 --> [394, 362, 311]\n",
            "628 --> [167, 305, 154]\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from langchain_text_splitters import NLTKTextSplitter\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def split_chunk(text):\n",
        "  # n= math.ceil(len(text)/512)\n",
        "  # text_splitter = SemanticChunker(embedding_function,  number_of_chunks=n)\n",
        "  text_splitter = NLTKTextSplitter(chunk_size=400)\n",
        "  result = text_splitter.split_text(text)\n",
        "  return result\n",
        "\n",
        "for i,text in enumerate(texts):\n",
        "  if len(text) > 512:\n",
        "    splited=split_chunk(text)\n",
        "    texts.pop(i)\n",
        "    texts.extend(splited)\n",
        "    print(f'{len(text)} --> {[len(t) for t in splited]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0NUvwPNPsCNA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5CjIPPdXJRDQ"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# model_path = 'Alibaba-NLP/gte-large-en-v1.5'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "# embedding_model = AutoModel.from_pretrained(model_path, trust_remote_code=True)\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import cos_sim\n",
        "from sentence_transformers.quantization import quantize_embeddings\n",
        "\n",
        "# 1. Specify preffered dimensions\n",
        "dimensions = 1024\n",
        "\n",
        "# 2. load model\n",
        "model = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", truncate_dim=dimensions)\n",
        "\n",
        "embeddings = model.encode(texts)\n",
        "\n",
        "# Optional: Quantize the embeddings\n",
        "binary_embeddings = quantize_embeddings(embeddings, precision=\"ubinary\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "azd8KSeGPAep"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "# batch_dict = tokenizer(texts, max_length=8192, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# outputs = embedding_model(**batch_dict)\n",
        "# embeddings = outputs.last_hidden_state[:, 0]\n",
        "\n",
        "# # (Optionally) normalize embeddings\n",
        "# embeddings = F.normalize(embeddings, p=2, dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jt3ex1y3ZxMb"
      },
      "outputs": [],
      "source": [
        "import chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jUXeczQPZvRh"
      },
      "outputs": [],
      "source": [
        "def store_embeddings(embeddings, chunks):\n",
        "    client = chromadb.Client()\n",
        "    collection = client.get_or_create_collection(\"pdf_embeddings\")\n",
        "    collection.upsert(documents=chunks,\n",
        "    embeddings=embeddings\n",
        "    ,ids=[str(i) for i in range(len(chunks)) ])\n",
        "    # for i, embedding in enumerate(embeddings):\n",
        "    #     collection.add_document(embedding=embedding.tolist(), document=chunks[i])\n",
        "    return collection,client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "yF4tdZ-g_A_0"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.embeddings import GPT4AllEmbeddings\n",
        "# from langchain_communai import OpenAIEmbeddings\n",
        "# vectorstore = Chroma.from_documents(documents=texts, embedding=binary_embeddings)\n",
        "\n",
        "collection, client = store_embeddings(embeddings, texts)\n",
        "\n",
        "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "\n",
        "# Define the embedding function using a pre-trained model\n",
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"mixedbread-ai/mxbai-embed-large-v1\")\n",
        "\n",
        "vector_store = Chroma(client=client, collection_name=\"pdf_embeddings\", embedding_function=embedding_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "LqEMS1i7pOSq"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZBopg-sIfR-"
      },
      "source": [
        "#  Section 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bD8A9urZ8dJ0",
        "outputId": "3ab9421d-20c4-4676-c3b9-d86bf9861d71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      31.04 ms /    57 runs   (    0.54 ms per token,  1836.10 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3910.20 ms /   432 tokens (    9.05 ms per token,   110.48 tokens per second)\n",
            "llama_print_timings:        eval time =    1986.75 ms /    57 runs   (   34.86 ms per token,    28.69 tokens per second)\n",
            "llama_print_timings:       total time =    6006.58 ms /   489 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Yes, you can use large language models for password modeling because many people tend to choose short and simple passwords that they can remember. These models can efficiently search through large dictionaries or word lists to discover a substantial fraction of all the passwords in a relatively short time.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain import hub\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "# Prompt\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "      Answer based on provided text only. Errors for out-of-context questions.\n",
        "      According to this document:\n",
        "       {context}\n",
        "      Please answer the following question: {question}\n",
        "      Answer:\"\"\"\n",
        ")\n",
        "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs if hasattr(doc, 'page_content'))\n",
        "    # print(formatted_docs)\n",
        "    return formatted_docs\n",
        "\n",
        "# chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
        "chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "question =\"Can I use large language models for password modeling?\"\n",
        "# docs = vector_store.similarity_search(question)\n",
        "# formatted_docs = format_docs(docs)\n",
        "# retrieval_chain = create_retrieval_chain(retriever, chain)\n",
        "# response = retrieval_chain.invoke(question)\n",
        "response = chain.invoke(question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fB8oEVjzUZCY",
        "outputId": "2e138a5e-834c-4814-bbde-76cfec661ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       4.56 ms /     9 runs   (    0.51 ms per token,  1972.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     483.14 ms /    59 tokens (    8.19 ms per token,   122.12 tokens per second)\n",
            "llama_print_timings:        eval time =     275.29 ms /     8 runs   (   34.41 ms per token,    29.06 tokens per second)\n",
            "llama_print_timings:       total time =     771.41 ms /    67 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Insufficient data to answer the question.\n"
          ]
        }
      ],
      "source": [
        "question =\"Does Dr. Bafghi look like a bear?\"\n",
        "response = chain.invoke(question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmO0UXUXaJCR",
        "outputId": "cd0c3e11-6d32-4bb8-e0ff-83060a8ab9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       7.68 ms /    15 runs   (    0.51 ms per token,  1954.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     303.47 ms /    38 tokens (    7.99 ms per token,   125.22 tokens per second)\n",
            "llama_print_timings:        eval time =     475.82 ms /    14 runs   (   33.99 ms per token,    29.42 tokens per second)\n",
            "llama_print_timings:       total time =     797.52 ms /    52 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " There is no information about \"LLM\" in the provided text.\n"
          ]
        }
      ],
      "source": [
        "question =\"what is LLM?\"\n",
        "response = chain.invoke(question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek8YXo4mqais",
        "outputId": "3710c5c6-b12f-43ee-f08a-ef0a53119075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      19.85 ms /    30 runs   (    0.66 ms per token,  1511.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3407.54 ms /   410 tokens (    8.31 ms per token,   120.32 tokens per second)\n",
            "llama_print_timings:        eval time =    1020.28 ms /    29 runs   (   35.18 ms per token,    28.42 tokens per second)\n",
            "llama_print_timings:       total time =    4485.73 ms /   439 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      10.30 ms /    17 runs   (    0.61 ms per token,  1649.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =     817.34 ms /    99 tokens (    8.26 ms per token,   121.13 tokens per second)\n",
            "llama_print_timings:        eval time =     562.11 ms /    16 runs   (   35.13 ms per token,    28.46 tokens per second)\n",
            "llama_print_timings:       total time =    1404.46 ms /   115 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.65 ms /     3 runs   (    0.55 ms per token,  1815.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3260.62 ms /   389 tokens (    8.38 ms per token,   119.30 tokens per second)\n",
            "llama_print_timings:        eval time =      71.34 ms /     2 runs   (   35.67 ms per token,    28.04 tokens per second)\n",
            "llama_print_timings:       total time =    3346.14 ms /   391 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      51.61 ms /    85 runs   (    0.61 ms per token,  1647.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    5241.96 ms /   619 tokens (    8.47 ms per token,   118.09 tokens per second)\n",
            "llama_print_timings:        eval time =    2992.62 ms /    84 runs   (   35.63 ms per token,    28.07 tokens per second)\n",
            "llama_print_timings:       total time =    8393.51 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      61.20 ms /   115 runs   (    0.53 ms per token,  1879.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3862.02 ms /   451 tokens (    8.56 ms per token,   116.78 tokens per second)\n",
            "llama_print_timings:        eval time =    4013.52 ms /   114 runs   (   35.21 ms per token,    28.40 tokens per second)\n",
            "llama_print_timings:       total time =    8404.64 ms /   565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      11.57 ms /    16 runs   (    0.72 ms per token,  1383.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3635.52 ms /   416 tokens (    8.74 ms per token,   114.43 tokens per second)\n",
            "llama_print_timings:        eval time =     537.50 ms /    15 runs   (   35.83 ms per token,    27.91 tokens per second)\n",
            "llama_print_timings:       total time =    4206.28 ms /   431 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      13.13 ms /    26 runs   (    0.50 ms per token,  1980.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3150.22 ms /   357 tokens (    8.82 ms per token,   113.33 tokens per second)\n",
            "llama_print_timings:        eval time =     879.71 ms /    25 runs   (   35.19 ms per token,    28.42 tokens per second)\n",
            "llama_print_timings:       total time =    4071.10 ms /   382 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      90.83 ms /   147 runs   (    0.62 ms per token,  1618.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3839.85 ms /   426 tokens (    9.01 ms per token,   110.94 tokens per second)\n",
            "llama_print_timings:        eval time =    5250.10 ms /   146 runs   (   35.96 ms per token,    27.81 tokens per second)\n",
            "llama_print_timings:       total time =    9324.22 ms /   572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      30.43 ms /    55 runs   (    0.55 ms per token,  1807.31 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3194.58 ms /   347 tokens (    9.21 ms per token,   108.62 tokens per second)\n",
            "llama_print_timings:        eval time =    1934.09 ms /    54 runs   (   35.82 ms per token,    27.92 tokens per second)\n",
            "llama_print_timings:       total time =    5207.91 ms /   401 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      25.75 ms /    45 runs   (    0.57 ms per token,  1747.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4866.61 ms /   524 tokens (    9.29 ms per token,   107.67 tokens per second)\n",
            "llama_print_timings:        eval time =    1597.98 ms /    44 runs   (   36.32 ms per token,    27.53 tokens per second)\n",
            "llama_print_timings:       total time =    6540.48 ms /   568 tokens\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    \"What is the primary goal of the password security scheme described in the paper?\",\n",
        "    \"Who are the authors of the paper and which institution are they associated with?\",\n",
        "    \"What system is the password security scheme implemented on?\",\n",
        "    \"What were some of the main problems with the original password file approach?\",\n",
        "    \"What is one method described for encrypting passwords in the improved scheme?\",\n",
        "    \"How does the key search technique work in attempting to crack passwords?\",\n",
        "    \"What was one of the key improvements made to the first encryption approach to enhance security?\",\n",
        "    \"Why are 'salted' passwords used and how do they improve security?\",\n",
        "    \"What role does user behavior play in password security according to the paper?\",\n",
        "    \"What is a real-world example of a security breach mentioned in the paper?\"\n",
        "]\n",
        "\n",
        "answers=[]\n",
        "for q in questions:\n",
        "  response = chain.invoke(q)\n",
        "  answers.append(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJFMy2cHqpeu",
        "outputId": "921d18b6-83a8-45ce-bc3b-46b897d63494"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' The primary goal of the password security scheme described in the paper is to provide password security at minimal inconvenience to the users of the system.',\n",
              " \" The authors' names and their associated institution cannot be determined from the provided text.\",\n",
              " ' UNIX',\n",
              " ' Some of the main problems with the original password file approach are that it was susceptible to high probability of going unnoticed by system administrators, security against unauthorized disclosure of the pass- words was impossible due to physical access to tapes and information being distributed or replicated into a number of files, and there was a need for updating all those files whenever changes were made to the users on the system.',\n",
              " ' The encrypted result is required, as before, to be the same as the remaining 64 bits in the password file. This modification does not increase the task of finding any individual password, starting from scratch, but now the work of testing a given character string against a large collection of encrypted passwords has been multiplied by 4,096 (212). The reason for this is that there are 4,096 encrypted versions of each password and one of them has been picked more or less at random by the system.',\n",
              " ' The key search technique works by trying potential passwords until one succeeds.',\n",
              " ' One of the key improvements made to the first encryption approach was to encrypt passwords for both valid and invalid user names.',\n",
              " \" Salted passwords are used to make it more difficult for potential attackers to use various key search techniques on a large collection of passwords, thus improving security. This is achieved by appending a 12-bit random number (also called the 'salt') to the original password before encrypting and storing it in the password file. When a user logs in, the same random number is extracted from the password file and combined with the entered password before attempting to decrypt and verify the password. This randomization process makes it harder for attackers to use precomputed tables or rainbow tables to crack the encrypted passwords, since each password is encrypted differently due to the varying salt values.\",\n",
              " ' According to the document, human beings tend to choose relatively short and simple passwords that they can remember. This habit makes it easier for an attacker to guess the password. Therefore, user behavior plays a significant role in determining the level of security provided by a password.',\n",
              " ' A real-world example of a security breach mentioned in the paper is when the temporary editor files of the two users were interchanged, causing the password file to be printed on every terminal when it was logged in.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf_Xr2zEJAPU"
      },
      "source": [
        "#  Section 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "aOt529tiNLxj"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import TokenTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "text=\"\"\n",
        "loader = PyPDFLoader(\"/content/1.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
        "\n",
        "docs = text_splitter.split_documents(pages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "k02tMnuxGAX2"
      },
      "outputs": [],
      "source": [
        "from langchain.storage import InMemoryByteStore\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "# from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "\n",
        "vector_store = Chroma(client=client, collection_name=\"pdf_embeddings\", embedding_function=embedding_function)\n",
        "\n",
        "store = InMemoryByteStore()\n",
        "id_key = \"doc_id\"\n",
        "# The retriever (empty to start)\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vector_store,\n",
        "    byte_store=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "import uuid\n",
        "\n",
        "doc_ids = [str(uuid.uuid4()) for _ in docs]\n",
        "    # Set up the vector store with LangChain\n",
        "# vector_store = Chroma.from_existing_collection(collection)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kcOWZMbJG2dn"
      },
      "outputs": [],
      "source": [
        "# # The splitter to use to create smaller chunks\n",
        "child_text_splitter = TokenTextSplitter(chunk_size=100, chunk_overlap=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eJHi7Bv9G33J"
      },
      "outputs": [],
      "source": [
        "sub_docs = []\n",
        "for i, doc in enumerate(docs):\n",
        "    _id = doc_ids[i]\n",
        "    _sub_docs = child_text_splitter.split_documents([doc])\n",
        "    for _doc in _sub_docs:\n",
        "        _doc.metadata[id_key] = _id\n",
        "    sub_docs.extend(_sub_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UaPISWq_G9Ku"
      },
      "outputs": [],
      "source": [
        "retriever.vectorstore.add_documents(sub_docs)\n",
        "retriever.docstore.mset(list(zip(doc_ids, docs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LFTfNFxFHThB"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_vector import SearchType\n",
        "\n",
        "retriever.search_type = SearchType.mmr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqjyiP9AJ3gZ",
        "outputId": "da72df5a-be3e-4af4-a64e-eb3237ce8192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      39.13 ms /    74 runs   (    0.53 ms per token,  1891.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =     525.75 ms /    63 tokens (    8.35 ms per token,   119.83 tokens per second)\n",
            "llama_print_timings:        eval time =    2551.58 ms /    73 runs   (   34.95 ms per token,    28.61 tokens per second)\n",
            "llama_print_timings:       total time =    3169.15 ms /   136 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Yes, you can use large language models for password modeling. These models have been trained on a vast amount of text data, which includes various types of passwords. By incorporating these models into your password generation process, you can benefit from their ability to create diverse and unique passwords by sampling from the extensive character set they've been exposed to during training.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Prompt\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "      Answer based on provided text only. Errors for out-of-context questions.\n",
        "      According to this document:\n",
        "       {context}\n",
        "      Please answer the following question: {question}\n",
        "\n",
        "      Answer:\"\"\"\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs if hasattr(doc, 'page_content'))\n",
        "    return formatted_docs\n",
        "\n",
        "chain2 = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "question =\"Can I use large language models for password modeling?\"\n",
        "response = chain2.invoke(question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jDNHxnGHnbti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "763baa7e-c207-4940-c99e-fc9563daf16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      12.05 ms /    26 runs   (    0.46 ms per token,  2156.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     533.43 ms /    64 tokens (    8.33 ms per token,   119.98 tokens per second)\n",
            "llama_print_timings:        eval time =     924.33 ms /    26 runs   (   35.55 ms per token,    28.13 tokens per second)\n",
            "llama_print_timings:       total time =    1488.52 ms /    90 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      15.00 ms /    29 runs   (    0.52 ms per token,  1933.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =     532.74 ms /    63 tokens (    8.46 ms per token,   118.26 tokens per second)\n",
            "llama_print_timings:        eval time =     975.48 ms /    28 runs   (   34.84 ms per token,    28.70 tokens per second)\n",
            "llama_print_timings:       total time =    1544.54 ms /    91 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       6.76 ms /    11 runs   (    0.61 ms per token,  1626.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =     297.96 ms /    34 tokens (    8.76 ms per token,   114.11 tokens per second)\n",
            "llama_print_timings:        eval time =     345.38 ms /    10 runs   (   34.54 ms per token,    28.95 tokens per second)\n",
            "llama_print_timings:       total time =     659.53 ms /    44 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      12.03 ms /    17 runs   (    0.71 ms per token,  1413.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =     435.67 ms /    50 tokens (    8.71 ms per token,   114.77 tokens per second)\n",
            "llama_print_timings:        eval time =     572.97 ms /    16 runs   (   35.81 ms per token,    27.92 tokens per second)\n",
            "llama_print_timings:       total time =    1040.01 ms /    66 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      15.31 ms /    24 runs   (    0.64 ms per token,  1567.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =     523.37 ms /    64 tokens (    8.18 ms per token,   122.28 tokens per second)\n",
            "llama_print_timings:        eval time =     813.50 ms /    23 runs   (   35.37 ms per token,    28.27 tokens per second)\n",
            "llama_print_timings:       total time =    1375.14 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      28.14 ms /    51 runs   (    0.55 ms per token,  1812.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =     314.87 ms /    37 tokens (    8.51 ms per token,   117.51 tokens per second)\n",
            "llama_print_timings:        eval time =    1733.76 ms /    50 runs   (   34.68 ms per token,    28.84 tokens per second)\n",
            "llama_print_timings:       total time =    2120.67 ms /    87 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       3.50 ms /     7 runs   (    0.50 ms per token,  1999.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     563.37 ms /    66 tokens (    8.54 ms per token,   117.15 tokens per second)\n",
            "llama_print_timings:        eval time =     206.57 ms /     6 runs   (   34.43 ms per token,    29.05 tokens per second)\n",
            "llama_print_timings:       total time =     779.50 ms /    72 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      91.18 ms /   171 runs   (    0.53 ms per token,  1875.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     445.92 ms /    52 tokens (    8.58 ms per token,   116.61 tokens per second)\n",
            "llama_print_timings:        eval time =    5858.08 ms /   170 runs   (   34.46 ms per token,    29.02 tokens per second)\n",
            "llama_print_timings:       total time =    6531.15 ms /   222 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       9.57 ms /    17 runs   (    0.56 ms per token,  1776.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =     439.74 ms /    52 tokens (    8.46 ms per token,   118.25 tokens per second)\n",
            "llama_print_timings:        eval time =     572.55 ms /    16 runs   (   35.78 ms per token,    27.95 tokens per second)\n",
            "llama_print_timings:       total time =    1039.42 ms /    68 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      13.25 ms /    21 runs   (    0.63 ms per token,  1585.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     507.36 ms /    60 tokens (    8.46 ms per token,   118.26 tokens per second)\n",
            "llama_print_timings:        eval time =     718.23 ms /    20 runs   (   35.91 ms per token,    27.85 tokens per second)\n",
            "llama_print_timings:       total time =    1260.18 ms /    80 tokens\n"
          ]
        }
      ],
      "source": [
        "questions = [\n",
        "    \"What is the primary goal of the password security scheme described in the paper?\",\n",
        "    \"Who are the authors of the paper and which institution are they associated with?\",\n",
        "    \"What system is the password security scheme implemented on?\",\n",
        "    \"What were some of the main problems with the original password file approach?\",\n",
        "    \"What is one method described for encrypting passwords in the improved scheme?\",\n",
        "    \"How does the key search technique work in attempting to crack passwords?\",\n",
        "    \"What was one of the key improvements made to the first encryption approach to enhance security?\",\n",
        "    \"Why are 'salted' passwords used and how do they improve security?\",\n",
        "    \"What role does user behavior play in password security according to the paper?\",\n",
        "    \"What is a real-world example of a security breach mentioned in the paper?\"\n",
        "]\n",
        "\n",
        "answers2=[]\n",
        "for q in questions:\n",
        "  response = chain2.invoke(q)\n",
        "  answers2.append(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MmVWJk9JL0u"
      },
      "source": [
        "#  Section summery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8uTNEnl-JhUS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd2b5f2f-2e74-45d2-fb28-bff476de1ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      20.18 ms /    38 runs   (    0.53 ms per token,  1883.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3639.74 ms /   461 tokens (    7.90 ms per token,   126.66 tokens per second)\n",
            "llama_print_timings:        eval time =    1274.79 ms /    37 runs   (   34.45 ms per token,    29.02 tokens per second)\n",
            "llama_print_timings:       total time =    4970.29 ms /   498 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      32.00 ms /    59 runs   (    0.54 ms per token,  1843.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1927.84 ms /   245 tokens (    7.87 ms per token,   127.09 tokens per second)\n",
            "llama_print_timings:        eval time =    1973.75 ms /    58 runs   (   34.03 ms per token,    29.39 tokens per second)\n",
            "llama_print_timings:       total time =    3978.07 ms /   303 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       2.47 ms /     4 runs   (    0.62 ms per token,  1622.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     492.01 ms /    63 tokens (    7.81 ms per token,   128.05 tokens per second)\n",
            "llama_print_timings:        eval time =     103.13 ms /     3 runs   (   34.38 ms per token,    29.09 tokens per second)\n",
            "llama_print_timings:       total time =     601.91 ms /    66 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       3.83 ms /     6 runs   (    0.64 ms per token,  1568.22 tokens per second)\n",
            "llama_print_timings: prompt eval time =     466.45 ms /    59 tokens (    7.91 ms per token,   126.49 tokens per second)\n",
            "llama_print_timings:        eval time =     171.30 ms /     5 runs   (   34.26 ms per token,    29.19 tokens per second)\n",
            "llama_print_timings:       total time =     647.08 ms /    64 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.24 ms /     2 runs   (    0.62 ms per token,  1616.81 tokens per second)\n",
            "llama_print_timings: prompt eval time =     922.74 ms /   115 tokens (    8.02 ms per token,   124.63 tokens per second)\n",
            "llama_print_timings:        eval time =      35.62 ms /     1 runs   (   35.62 ms per token,    28.07 tokens per second)\n",
            "llama_print_timings:       total time =     963.43 ms /   116 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      16.93 ms /    36 runs   (    0.47 ms per token,  2126.15 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1738.93 ms /   219 tokens (    7.94 ms per token,   125.94 tokens per second)\n",
            "llama_print_timings:        eval time =    1188.45 ms /    35 runs   (   33.96 ms per token,    29.45 tokens per second)\n",
            "llama_print_timings:       total time =    2965.77 ms /   254 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      34.37 ms /    65 runs   (    0.53 ms per token,  1891.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3299.87 ms /   411 tokens (    8.03 ms per token,   124.55 tokens per second)\n",
            "llama_print_timings:        eval time =    2203.26 ms /    64 runs   (   34.43 ms per token,    29.05 tokens per second)\n",
            "llama_print_timings:       total time =    5587.12 ms /   475 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      67.31 ms /   108 runs   (    0.62 ms per token,  1604.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3919.51 ms /   484 tokens (    8.10 ms per token,   123.48 tokens per second)\n",
            "llama_print_timings:        eval time =    3761.63 ms /   107 runs   (   35.16 ms per token,    28.45 tokens per second)\n",
            "llama_print_timings:       total time =    7859.23 ms /   591 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      37.61 ms /    73 runs   (    0.52 ms per token,  1940.92 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2445.80 ms /   303 tokens (    8.07 ms per token,   123.89 tokens per second)\n",
            "llama_print_timings:        eval time =    2473.24 ms /    72 runs   (   34.35 ms per token,    29.11 tokens per second)\n",
            "llama_print_timings:       total time =    5016.30 ms /   375 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      18.21 ms /    34 runs   (    0.54 ms per token,  1867.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     881.42 ms /   107 tokens (    8.24 ms per token,   121.40 tokens per second)\n",
            "llama_print_timings:        eval time =    1117.78 ms /    33 runs   (   33.87 ms per token,    29.52 tokens per second)\n",
            "llama_print_timings:       total time =    2040.98 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      16.71 ms /    33 runs   (    0.51 ms per token,  1974.87 tokens per second)\n",
            "llama_print_timings: prompt eval time =    4358.27 ms /   523 tokens (    8.33 ms per token,   120.00 tokens per second)\n",
            "llama_print_timings:        eval time =    1121.35 ms /    32 runs   (   35.04 ms per token,    28.54 tokens per second)\n",
            "llama_print_timings:       total time =    5529.31 ms /   555 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  2002.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1024.53 ms /   123 tokens (    8.33 ms per token,   120.05 tokens per second)\n",
            "llama_print_timings:        eval time =      34.77 ms /     1 runs   (   34.77 ms per token,    28.76 tokens per second)\n",
            "llama_print_timings:       total time =    1063.83 ms /   124 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      14.66 ms /    28 runs   (    0.52 ms per token,  1909.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1745.09 ms /   210 tokens (    8.31 ms per token,   120.34 tokens per second)\n",
            "llama_print_timings:        eval time =     924.32 ms /    27 runs   (   34.23 ms per token,    29.21 tokens per second)\n",
            "llama_print_timings:       total time =    2706.30 ms /   237 tokens\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Requested tokens (909) exceed context window of 800",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-7fb541b83cf3>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"max_concurrency\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m   2632\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m                     inputs = step.batch(\n\u001b[0m\u001b[1;32m   2635\u001b[0m                         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m                         [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m             ]\n\u001b[1;32m    346\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_concurrency\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    348\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                 for output in self.batch(\n\u001b[0m\u001b[1;32m    351\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_concurrency\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_concurrency\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             batches = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mbatch\u001b[0;34m(self, inputs, config, return_exceptions, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_concurrency\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 llm_result = self.generate_prompt(\n\u001b[0m\u001b[1;32m    328\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    632\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[0;32m--> 803\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    804\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             output = (\n\u001b[0;32m--> 657\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    658\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             text = (\n\u001b[0;32m-> 1317\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/llamacpp.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# and return the combined strings from the first choices's text:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mcombined_text_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             for chunk in self._stream(\n\u001b[0m\u001b[1;32m    289\u001b[0m                 \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/llms/llamacpp.py\u001b[0m in \u001b[0;36m_stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mlogprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"choices\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logprobs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             chunk = GenerationChunk(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/llama_cpp/llama.py\u001b[0m in \u001b[0;36m_create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_tokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1049\u001b[0m                 \u001b[0;34mf\"Requested tokens ({len(prompt_tokens)}) exceed context window of {llama_cpp.llama_n_ctx(self.ctx)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Requested tokens (909) exceed context window of 800"
          ]
        }
      ],
      "source": [
        "# import uuid\n",
        "\n",
        "# from langchain_core.documents import Document\n",
        "# from langchain_core.output_parsers import StrOutputParser\n",
        "# from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# chain_summery = (\n",
        "#     {\"doc\":lambda x:x}\n",
        "#     | ChatPromptTemplate.from_template(\"Summarize the following document:\\n\\n{doc}\")\n",
        "#     | llm\n",
        "#     | StrOutputParser()\n",
        "# )\n",
        "# summaries = chain.batch(texts, {\"max_concurrency\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhTgRyHYKMts"
      },
      "outputs": [],
      "source": [
        "# # The vectorstore to use to index the child chunks\n",
        "# vectorstore = Chroma(collection_name=\"summaries\", embedding_function=embedding_function)\n",
        "# # The storage layer for the parent documents\n",
        "# store = InMemoryByteStore()\n",
        "# id_key = \"doc_id\"\n",
        "# # The retriever (empty to start)\n",
        "# retriever = MultiVectorRetriever(\n",
        "#     vectorstore=vector_store,\n",
        "#     byte_store=store,\n",
        "#     id_key=id_key,\n",
        "# )\n",
        "# doc_ids = [str(uuid.uuid4()) for _ in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHUsdkyZKfXV"
      },
      "outputs": [],
      "source": [
        "# summary_docs = [\n",
        "#     Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "#     for i, s in enumerate(summaries)\n",
        "# ]\n",
        "# retriever.vectorstore.add_documents(summary_docs)\n",
        "# retriever.docstore.mset(list(zip(doc_ids, docs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eI4OLTQwJQcX"
      },
      "outputs": [],
      "source": [
        "# from langchain_core.output_parsers import StrOutputParser\n",
        "# from langchain_core.prompts import PromptTemplate\n",
        "# from langchain.chains import create_retrieval_chain\n",
        "# from langchain import hub\n",
        "# from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
        "# from langchain_core.runnables import RunnablePassthrough\n",
        "# # Prompt\n",
        "\n",
        "# prompt = PromptTemplate.from_template(\n",
        "#     \"\"\"\n",
        "#       Answer based on provided text only. Errors for out-of-context questions.\n",
        "#       According to this document:\n",
        "#        {context}\n",
        "#       Please answer the following question: {question}\n",
        "\n",
        "#       Answer:\"\"\"\n",
        "# )\n",
        "# # prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "# def format_docs(docs):\n",
        "#     formatted_docs = \"\\n\\n\".join(doc.page_content for doc in docs if hasattr(doc, 'page_content'))\n",
        "#     # print(formatted_docs)\n",
        "#     return formatted_docs\n",
        "\n",
        "# # chain = {\"docs\": format_docs} | prompt | llm | StrOutputParser()\n",
        "# chain3 = (\n",
        "#     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "#     | prompt\n",
        "#     | llm\n",
        "#     | StrOutputParser()\n",
        "# )\n",
        "\n",
        "# question =\"Can I use large language models for password modeling?\"\n",
        "# response = chain3.invoke(question)\n",
        "# print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLLPiEbxLviG"
      },
      "outputs": [],
      "source": [
        "# questions = [\n",
        "#     \"What is the primary goal of the password security scheme described in the paper?\",\n",
        "#     \"Who are the authors of the paper and which institution are they associated with?\",\n",
        "#     \"What system is the password security scheme implemented on?\",\n",
        "#     \"What were some of the main problems with the original password file approach?\",\n",
        "#     \"What is one method described for encrypting passwords in the improved scheme?\",\n",
        "#     \"How does the key search technique work in attempting to crack passwords?\",\n",
        "#     \"What was one of the key improvements made to the first encryption approach to enhance security?\",\n",
        "#     \"Why are 'salted' passwords used and how do they improve security?\",\n",
        "#     \"What role does user behavior play in password security according to the paper?\",\n",
        "#     \"What is a real-world example of a security breach mentioned in the paper?\"\n",
        "# ]\n",
        "\n",
        "# answer3=[]\n",
        "# for q in questions:\n",
        "#   response = chain3.invoke(q)\n",
        "#   answer3.append(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycdh_LqayRc-"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xyjAq_1e0IEy"
      },
      "outputs": [],
      "source": [
        "context=''.join(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "eIyoHmjW4vtN"
      },
      "outputs": [],
      "source": [
        "eval_llm = llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ur23ryQxyX9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b835f41e-1448-4037-8545-97ad4977dd20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      92.68 ms /   157 runs   (    0.59 ms per token,  1693.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1096.40 ms /   131 tokens (    8.37 ms per token,   119.48 tokens per second)\n",
            "llama_print_timings:        eval time =    5287.90 ms /   156 runs   (   33.90 ms per token,    29.50 tokens per second)\n",
            "llama_print_timings:       total time =    6618.34 ms /   287 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =     136.98 ms /   256 runs   (    0.54 ms per token,  1868.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =     648.54 ms /    82 tokens (    7.91 ms per token,   126.44 tokens per second)\n",
            "llama_print_timings:        eval time =    8616.82 ms /   255 runs   (   33.79 ms per token,    29.59 tokens per second)\n",
            "llama_print_timings:       total time =    9626.53 ms /   337 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      54.59 ms /    94 runs   (    0.58 ms per token,  1721.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =     781.65 ms /    99 tokens (    7.90 ms per token,   126.66 tokens per second)\n",
            "llama_print_timings:        eval time =    3134.76 ms /    93 runs   (   33.71 ms per token,    29.67 tokens per second)\n",
            "llama_print_timings:       total time =    4039.80 ms /   192 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       2.08 ms /     4 runs   (    0.52 ms per token,  1921.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =     805.82 ms /   104 tokens (    7.75 ms per token,   129.06 tokens per second)\n",
            "llama_print_timings:        eval time =     102.48 ms /     3 runs   (   34.16 ms per token,    29.28 tokens per second)\n",
            "llama_print_timings:       total time =     914.62 ms /   107 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      72.92 ms /   139 runs   (    0.52 ms per token,  1906.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     467.76 ms /    61 tokens (    7.67 ms per token,   130.41 tokens per second)\n",
            "llama_print_timings:        eval time =    4636.99 ms /   138 runs   (   33.60 ms per token,    29.76 tokens per second)\n",
            "llama_print_timings:       total time =    5273.26 ms /   199 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =     145.78 ms /   256 runs   (    0.57 ms per token,  1756.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     489.71 ms /    62 tokens (    7.90 ms per token,   126.60 tokens per second)\n",
            "llama_print_timings:        eval time =    8660.56 ms /   255 runs   (   33.96 ms per token,    29.44 tokens per second)\n",
            "llama_print_timings:       total time =    9529.02 ms /   317 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.88 ms /     3 runs   (    0.63 ms per token,  1594.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1866.05 ms /   232 tokens (    8.04 ms per token,   124.33 tokens per second)\n",
            "llama_print_timings:        eval time =      70.18 ms /     2 runs   (   35.09 ms per token,    28.50 tokens per second)\n",
            "llama_print_timings:       total time =    1944.66 ms /   234 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      25.94 ms /    49 runs   (    0.53 ms per token,  1888.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     609.74 ms /    78 tokens (    7.82 ms per token,   127.92 tokens per second)\n",
            "llama_print_timings:        eval time =    1617.32 ms /    48 runs   (   33.69 ms per token,    29.68 tokens per second)\n",
            "llama_print_timings:       total time =    2283.89 ms /   126 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.57 ms /     2 runs   (    0.79 ms per token,  1272.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    2406.00 ms /   296 tokens (    8.13 ms per token,   123.03 tokens per second)\n",
            "llama_print_timings:        eval time =      35.53 ms /     1 runs   (   35.53 ms per token,    28.14 tokens per second)\n",
            "llama_print_timings:       total time =    2450.97 ms /   297 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =     133.12 ms /   256 runs   (    0.52 ms per token,  1923.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     749.60 ms /    94 tokens (    7.97 ms per token,   125.40 tokens per second)\n",
            "llama_print_timings:        eval time =    8693.11 ms /   255 runs   (   34.09 ms per token,    29.33 tokens per second)\n",
            "llama_print_timings:       total time =    9790.59 ms /   349 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     3 runs   (    0.51 ms per token,  1980.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     770.97 ms /    95 tokens (    8.12 ms per token,   123.22 tokens per second)\n",
            "llama_print_timings:        eval time =      69.04 ms /     2 runs   (   34.52 ms per token,    28.97 tokens per second)\n",
            "llama_print_timings:       total time =     844.52 ms /    97 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.52 ms /     2 runs   (    0.76 ms per token,  1316.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1151.83 ms /   139 tokens (    8.29 ms per token,   120.68 tokens per second)\n",
            "llama_print_timings:        eval time =      35.15 ms /     1 runs   (   35.15 ms per token,    28.45 tokens per second)\n",
            "llama_print_timings:       total time =    1193.01 ms /   140 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       2.82 ms /     4 runs   (    0.71 ms per token,  1417.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     972.96 ms /   120 tokens (    8.11 ms per token,   123.33 tokens per second)\n",
            "llama_print_timings:        eval time =     139.50 ms /     4 runs   (   34.88 ms per token,    28.67 tokens per second)\n",
            "llama_print_timings:       total time =    1121.22 ms /   124 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =     130.37 ms /   256 runs   (    0.51 ms per token,  1963.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =     492.03 ms /    61 tokens (    8.07 ms per token,   123.98 tokens per second)\n",
            "llama_print_timings:        eval time =    8712.76 ms /   255 runs   (   34.17 ms per token,    29.27 tokens per second)\n",
            "llama_print_timings:       total time =    9550.97 ms /   316 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       2.93 ms /     4 runs   (    0.73 ms per token,  1366.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3027.89 ms /   364 tokens (    8.32 ms per token,   120.22 tokens per second)\n",
            "llama_print_timings:        eval time =     108.15 ms /     3 runs   (   36.05 ms per token,    27.74 tokens per second)\n",
            "llama_print_timings:       total time =    3149.44 ms /   367 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       9.96 ms /    18 runs   (    0.55 ms per token,  1807.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    3196.07 ms /   383 tokens (    8.34 ms per token,   119.83 tokens per second)\n",
            "llama_print_timings:        eval time =     589.59 ms /    17 runs   (   34.68 ms per token,    28.83 tokens per second)\n",
            "llama_print_timings:       total time =    3818.77 ms /   400 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       2.22 ms /     4 runs   (    0.56 ms per token,  1801.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1442.77 ms /   174 tokens (    8.29 ms per token,   120.60 tokens per second)\n",
            "llama_print_timings:        eval time =     103.31 ms /     3 runs   (   34.44 ms per token,    29.04 tokens per second)\n",
            "llama_print_timings:       total time =    1553.67 ms /   177 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       2.52 ms /     5 runs   (    0.50 ms per token,  1986.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     625.43 ms /    78 tokens (    8.02 ms per token,   124.71 tokens per second)\n",
            "llama_print_timings:        eval time =     138.69 ms /     4 runs   (   34.67 ms per token,    28.84 tokens per second)\n",
            "llama_print_timings:       total time =     771.09 ms /    82 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =       1.08 ms /     2 runs   (    0.54 ms per token,  1845.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1309.87 ms /   158 tokens (    8.29 ms per token,   120.62 tokens per second)\n",
            "llama_print_timings:        eval time =      35.59 ms /     1 runs   (   35.59 ms per token,    28.10 tokens per second)\n",
            "llama_print_timings:       total time =    1350.28 ms /   159 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     355.64 ms\n",
            "llama_print_timings:      sample time =      26.39 ms /    51 runs   (    0.52 ms per token,  1932.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =     749.20 ms /    90 tokens (    8.32 ms per token,   120.13 tokens per second)\n",
            "llama_print_timings:        eval time =    1702.68 ms /    50 runs   (   34.05 ms per token,    29.37 tokens per second)\n",
            "llama_print_timings:       total time =    2512.04 ms /   140 tokens\n"
          ]
        }
      ],
      "source": [
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "      question: {question}\n",
        "      answer: {ans}\n",
        "      Please just give score for answer in range 0-10\n",
        "      \"\"\"\n",
        ")\n",
        "\n",
        "eval_chain = (\n",
        "    {\"question\": RunnablePassthrough(),\"ans\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | eval_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "score1=[]\n",
        "score2=[]\n",
        "for q,answer1,answer2 in zip(questions,answers,answers2):\n",
        "  r1 = eval_chain.invoke({'question':q,'ans':answer1})\n",
        "  r2 = eval_chain.invoke({'question':q,'ans':answer2})\n",
        "  score1.append(r1.split()[0])\n",
        "  score2.append(r2.split()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame({\n",
        "    'query':questions,\n",
        "    'answer1':answers,\n",
        "    'answer2':answers2,\n",
        "    'score1': score1,\n",
        "    'score2': score2,\n",
        "    })\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1742
        },
        "id": "FiNFxPslP11U",
        "outputId": "889d208b-6db6-4244-f92f-e1fff05324d7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               query  \\\n",
              "0  What is the primary goal of the password secur...   \n",
              "1  Who are the authors of the paper and which ins...   \n",
              "2  What system is the password security scheme im...   \n",
              "3  What were some of the main problems with the o...   \n",
              "4  What is one method described for encrypting pa...   \n",
              "5  How does the key search technique work in atte...   \n",
              "6  What was one of the key improvements made to t...   \n",
              "7  Why are 'salted' passwords used and how do the...   \n",
              "8  What role does user behavior play in password ...   \n",
              "9  What is a real-world example of a security bre...   \n",
              "\n",
              "                                             answer1  \\\n",
              "0   The primary goal of the password security sch...   \n",
              "1   The authors' names and their associated insti...   \n",
              "2                                               UNIX   \n",
              "3   Some of the main problems with the original p...   \n",
              "4   The encrypted result is required, as before, ...   \n",
              "5   The key search technique works by trying pote...   \n",
              "6   One of the key improvements made to the first...   \n",
              "7   Salted passwords are used to make it more dif...   \n",
              "8   According to the document, human beings tend ...   \n",
              "9   A real-world example of a security breach men...   \n",
              "\n",
              "                                             answer2              score1  \\\n",
              "0   The primary goal of the password security sch...  0.8935574564446922   \n",
              "1   The authors of the paper are G. H. Golomb and...                 0.0   \n",
              "2   The system is not specified in the provided t...                  1.   \n",
              "3   There are no main problems mentioned with the...                  10   \n",
              "4   One method described for encrypting passwords...                   3   \n",
              "5   The key search technique works by trying diff...                  10   \n",
              "6                     Using an encrypted dictionary.                 7.5   \n",
              "7   Salted passwords are used in order to enhance...                 6.5   \n",
              "8   The text does not provide information about t...                 6.8   \n",
              "9   There isn't any specific real-world example o...                   8   \n",
              "\n",
              "               score2  \n",
              "0                 8.5  \n",
              "1                 7.5  \n",
              "2                   3  \n",
              "3                   9  \n",
              "4  2.7869459395741775  \n",
              "5                   5  \n",
              "6                   7  \n",
              "7                   7  \n",
              "8                5/10  \n",
              "9                   0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4637c295-4024-44e2-b529-f1f8ab4e0eec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>answer1</th>\n",
              "      <th>answer2</th>\n",
              "      <th>score1</th>\n",
              "      <th>score2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the primary goal of the password secur...</td>\n",
              "      <td>The primary goal of the password security sch...</td>\n",
              "      <td>The primary goal of the password security sch...</td>\n",
              "      <td>0.8935574564446922</td>\n",
              "      <td>8.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who are the authors of the paper and which ins...</td>\n",
              "      <td>The authors' names and their associated insti...</td>\n",
              "      <td>The authors of the paper are G. H. Golomb and...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What system is the password security scheme im...</td>\n",
              "      <td>UNIX</td>\n",
              "      <td>The system is not specified in the provided t...</td>\n",
              "      <td>1.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What were some of the main problems with the o...</td>\n",
              "      <td>Some of the main problems with the original p...</td>\n",
              "      <td>There are no main problems mentioned with the...</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is one method described for encrypting pa...</td>\n",
              "      <td>The encrypted result is required, as before, ...</td>\n",
              "      <td>One method described for encrypting passwords...</td>\n",
              "      <td>3</td>\n",
              "      <td>2.7869459395741775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How does the key search technique work in atte...</td>\n",
              "      <td>The key search technique works by trying pote...</td>\n",
              "      <td>The key search technique works by trying diff...</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What was one of the key improvements made to t...</td>\n",
              "      <td>One of the key improvements made to the first...</td>\n",
              "      <td>Using an encrypted dictionary.</td>\n",
              "      <td>7.5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why are 'salted' passwords used and how do the...</td>\n",
              "      <td>Salted passwords are used to make it more dif...</td>\n",
              "      <td>Salted passwords are used in order to enhance...</td>\n",
              "      <td>6.5</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What role does user behavior play in password ...</td>\n",
              "      <td>According to the document, human beings tend ...</td>\n",
              "      <td>The text does not provide information about t...</td>\n",
              "      <td>6.8</td>\n",
              "      <td>5/10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is a real-world example of a security bre...</td>\n",
              "      <td>A real-world example of a security breach men...</td>\n",
              "      <td>There isn't any specific real-world example o...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4637c295-4024-44e2-b529-f1f8ab4e0eec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4637c295-4024-44e2-b529-f1f8ab4e0eec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4637c295-4024-44e2-b529-f1f8ab4e0eec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ec9ec11-de81-423d-8515-d3f518870000\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ec9ec11-de81-423d-8515-d3f518870000')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ec9ec11-de81-423d-8515-d3f518870000 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What role does user behavior play in password security according to the paper?\",\n          \"Who are the authors of the paper and which institution are they associated with?\",\n          \"How does the key search technique work in attempting to crack passwords?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \" According to the document, human beings tend to choose relatively short and simple passwords that they can remember. This habit makes it easier for an attacker to guess the password. Therefore, user behavior plays a significant role in determining the level of security provided by a password.\",\n          \" The authors' names and their associated institution cannot be determined from the provided text.\",\n          \" The key search technique works by trying potential passwords until one succeeds.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \" The text does not provide information about the role of user behavior in password security.\",\n          \" The authors of the paper are G. H. Golomb and M. E. Hopkins and they are associated with Bell Labs.\",\n          \" The key search technique works by trying different possible keys (or combinations of characters and numbers) until it finds the correct combination that matches the given password. This method can be time-consuming and difficult, as there are many possible combinations to try.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"6.8\",\n          \"0.0\",\n          \"7.5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"5/10\",\n          \"7.5\",\n          \"5\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "562963851f564cdba383a9c4be90016c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04ad1d1452b64542a0cefca03260a8f8",
              "IPY_MODEL_98e637ae57174f21927145d2d210ec57",
              "IPY_MODEL_bd932ec714f54e41b61819bbc9be2a9b"
            ],
            "layout": "IPY_MODEL_df2cd4e7a0e641ebadc34f5980389af6"
          }
        },
        "04ad1d1452b64542a0cefca03260a8f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e0613ef28e45bb8accee36e0fc27bd",
            "placeholder": "​",
            "style": "IPY_MODEL_65cfcd8af0e1430d8374b30e258462e8",
            "value": "mistral-7b-openorca.Q8_0.gguf: 100%"
          }
        },
        "98e637ae57174f21927145d2d210ec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a1e6b2ecda647839bf9d6518b861757",
            "max": 7695874752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e461879d1ae14048ac407bbbcac7da77",
            "value": 7695874752
          }
        },
        "bd932ec714f54e41b61819bbc9be2a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c7e245824e648c3a6b5658435471623",
            "placeholder": "​",
            "style": "IPY_MODEL_45b4b5d4ee3e46f396a5003bf348e5a0",
            "value": " 7.70G/7.70G [00:56&lt;00:00, 205MB/s]"
          }
        },
        "df2cd4e7a0e641ebadc34f5980389af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e0613ef28e45bb8accee36e0fc27bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65cfcd8af0e1430d8374b30e258462e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a1e6b2ecda647839bf9d6518b861757": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e461879d1ae14048ac407bbbcac7da77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c7e245824e648c3a6b5658435471623": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b4b5d4ee3e46f396a5003bf348e5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab4eb4819d6466abef85b9be0c29497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aac560be7b3e4582a8554b6bf0452dc1",
              "IPY_MODEL_dc724b49fa8247fba6e2d8d2fc98f13f",
              "IPY_MODEL_faad74d825f346d38bb83cdebf05719a"
            ],
            "layout": "IPY_MODEL_11a8470b5aef4255b0ab71f6d8f9acba"
          }
        },
        "aac560be7b3e4582a8554b6bf0452dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_861733038fd94d028a43bba0b335b7ad",
            "placeholder": "​",
            "style": "IPY_MODEL_1b758ef90b8b4bd88b4a9ad928a7d1c5",
            "value": "modules.json: 100%"
          }
        },
        "dc724b49fa8247fba6e2d8d2fc98f13f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc257e4a2a54dd49f129b44428bd5f7",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34ffd9f3df0a433dbbb22bc497bc8b76",
            "value": 229
          }
        },
        "faad74d825f346d38bb83cdebf05719a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f91e9e7ef2564f5b928cdc201a0a0172",
            "placeholder": "​",
            "style": "IPY_MODEL_29d2ed3f3f254264865c83e0378d5cfd",
            "value": " 229/229 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "11a8470b5aef4255b0ab71f6d8f9acba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861733038fd94d028a43bba0b335b7ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b758ef90b8b4bd88b4a9ad928a7d1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fc257e4a2a54dd49f129b44428bd5f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34ffd9f3df0a433dbbb22bc497bc8b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f91e9e7ef2564f5b928cdc201a0a0172": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29d2ed3f3f254264865c83e0378d5cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b009fce674d4675901088c10fd036af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66144d0b62f244cba8b3c5f9255733ba",
              "IPY_MODEL_97556ec181d542af980fb30cc1a66cb4",
              "IPY_MODEL_87e318d8871b456889686cbd0752656c"
            ],
            "layout": "IPY_MODEL_038dcf017015418d89c41f220e87f978"
          }
        },
        "66144d0b62f244cba8b3c5f9255733ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5078c75c25c747c880ce6b3e16a41c74",
            "placeholder": "​",
            "style": "IPY_MODEL_38a99ade60c84f8bb785c0fcd04feded",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "97556ec181d542af980fb30cc1a66cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1a17506eaa04fd596f9f8c08d5c52b0",
            "max": 171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35b7a43577bd4540b5ba5534105bf3f8",
            "value": 171
          }
        },
        "87e318d8871b456889686cbd0752656c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1050fa2a2b641e7bcecb53f584a283c",
            "placeholder": "​",
            "style": "IPY_MODEL_cd29fc5f99e14130ab64bdfedf117a1e",
            "value": " 171/171 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "038dcf017015418d89c41f220e87f978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5078c75c25c747c880ce6b3e16a41c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a99ade60c84f8bb785c0fcd04feded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1a17506eaa04fd596f9f8c08d5c52b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b7a43577bd4540b5ba5534105bf3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1050fa2a2b641e7bcecb53f584a283c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd29fc5f99e14130ab64bdfedf117a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31059df6003d49f1994f87c409e5f19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e1acb074d1f47d38335c1684ae7e337",
              "IPY_MODEL_b904bc84290547c98aadf2c2ed3d4773",
              "IPY_MODEL_69c9ac87c0f84ff194ee78b3e8aebaa9"
            ],
            "layout": "IPY_MODEL_c0915161597a4e1180800e7229d01440"
          }
        },
        "5e1acb074d1f47d38335c1684ae7e337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ac986a1d0a4266a26ef914640f7e50",
            "placeholder": "​",
            "style": "IPY_MODEL_0344fe41cee24a13b773902315f236d8",
            "value": "README.md: 100%"
          }
        },
        "b904bc84290547c98aadf2c2ed3d4773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d36bd834b8bd4db492ba4074ed4459b6",
            "max": 113474,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af28a4eab1c0489ebc2ab6f519230fdc",
            "value": 113474
          }
        },
        "69c9ac87c0f84ff194ee78b3e8aebaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_341fb06bf89c47928b5c14ec9710a1fd",
            "placeholder": "​",
            "style": "IPY_MODEL_65b61104c20b4633a6d975e98e306d2a",
            "value": " 113k/113k [00:00&lt;00:00, 4.73MB/s]"
          }
        },
        "c0915161597a4e1180800e7229d01440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ac986a1d0a4266a26ef914640f7e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0344fe41cee24a13b773902315f236d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d36bd834b8bd4db492ba4074ed4459b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af28a4eab1c0489ebc2ab6f519230fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "341fb06bf89c47928b5c14ec9710a1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b61104c20b4633a6d975e98e306d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03e117ecec6e4bbab262a559f0d3c98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb0e9eba827444d7be2693250ad34298",
              "IPY_MODEL_de4ec3674a55449abfb8e3fb09f2e9ae",
              "IPY_MODEL_b1b14448a0604c3598650f118b65a5ed"
            ],
            "layout": "IPY_MODEL_08645085b2614e79b19e150f628a237f"
          }
        },
        "eb0e9eba827444d7be2693250ad34298": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd78d00546f4b86b9ba6ef523432469",
            "placeholder": "​",
            "style": "IPY_MODEL_734785855dc341a99681c4b238265c99",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "de4ec3674a55449abfb8e3fb09f2e9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_035679c60eab45518a8017f0c1ede4c5",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa9f9a39081d4700ae4f0e4e91d9b4bc",
            "value": 53
          }
        },
        "b1b14448a0604c3598650f118b65a5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33576d4c08034d6e8a717dd4f9ed3ae2",
            "placeholder": "​",
            "style": "IPY_MODEL_f4b7760a74b94b2c811aedead8506de8",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.34kB/s]"
          }
        },
        "08645085b2614e79b19e150f628a237f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd78d00546f4b86b9ba6ef523432469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734785855dc341a99681c4b238265c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "035679c60eab45518a8017f0c1ede4c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9f9a39081d4700ae4f0e4e91d9b4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33576d4c08034d6e8a717dd4f9ed3ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b7760a74b94b2c811aedead8506de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfe7e8f8d33e419ebae4ce877f2cde2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ccb5a9689d84d1da4779f88c5e51e6c",
              "IPY_MODEL_8c2f6d986ad247a297ba215f4c2e4c62",
              "IPY_MODEL_1397cf2b626547bc9a3be1e203c8b17c"
            ],
            "layout": "IPY_MODEL_129c385dadd14e3294046b03863a1b1b"
          }
        },
        "7ccb5a9689d84d1da4779f88c5e51e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4404a9b43c994d40aea040c10e73a842",
            "placeholder": "​",
            "style": "IPY_MODEL_90464ecea2e64826973167ea63478614",
            "value": "config.json: 100%"
          }
        },
        "8c2f6d986ad247a297ba215f4c2e4c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_556dee3bc11540849436b0ac3a70b8e1",
            "max": 677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a59fa2fa767468bab1acb6a2894132e",
            "value": 677
          }
        },
        "1397cf2b626547bc9a3be1e203c8b17c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b09a2405a5347068af1c38a46778cfb",
            "placeholder": "​",
            "style": "IPY_MODEL_174bfa6897b14a749e97a623d48057d8",
            "value": " 677/677 [00:00&lt;00:00, 57.1kB/s]"
          }
        },
        "129c385dadd14e3294046b03863a1b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4404a9b43c994d40aea040c10e73a842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90464ecea2e64826973167ea63478614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "556dee3bc11540849436b0ac3a70b8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a59fa2fa767468bab1acb6a2894132e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b09a2405a5347068af1c38a46778cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174bfa6897b14a749e97a623d48057d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4754bdf3fb049bf8dd3c8228d75e536": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30ab57c8850f42afa5f574b3a4c9fe49",
              "IPY_MODEL_a3b6f5dbf7664734ba617094b8a087f2",
              "IPY_MODEL_b56fdd0d006b47a8952c635ca958b40e"
            ],
            "layout": "IPY_MODEL_5d4afa99f123446084fb8be33161373c"
          }
        },
        "30ab57c8850f42afa5f574b3a4c9fe49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6e0f6cf22246ab8813ed6d02d341ac",
            "placeholder": "​",
            "style": "IPY_MODEL_588b5b11216a42bfab6443edb4a8cd91",
            "value": "model.safetensors: 100%"
          }
        },
        "a3b6f5dbf7664734ba617094b8a087f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34fa27c0b79a4fdba60329822c59a2a3",
            "max": 670328392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d366b9cf8d3f4cd6b5d905286e27452a",
            "value": 670328392
          }
        },
        "b56fdd0d006b47a8952c635ca958b40e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_737bcae6205640e191e6c3921d3b0473",
            "placeholder": "​",
            "style": "IPY_MODEL_c44f952f5c06453fa19a6b57c2859134",
            "value": " 670M/670M [00:06&lt;00:00, 114MB/s]"
          }
        },
        "5d4afa99f123446084fb8be33161373c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6e0f6cf22246ab8813ed6d02d341ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588b5b11216a42bfab6443edb4a8cd91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34fa27c0b79a4fdba60329822c59a2a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d366b9cf8d3f4cd6b5d905286e27452a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "737bcae6205640e191e6c3921d3b0473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c44f952f5c06453fa19a6b57c2859134": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "558d2c121aae4d6fbf5e8d8a5835a4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a3df9385f7d49c193c1e3c0183a4265",
              "IPY_MODEL_a77c1437cf16482fac6aa75efe5fdd2c",
              "IPY_MODEL_c77e7c6406ea488e93d469ef585a7aca"
            ],
            "layout": "IPY_MODEL_d6f7195b32784f32ae57357e913e8aad"
          }
        },
        "2a3df9385f7d49c193c1e3c0183a4265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d0885a1220c48359fb93a5fc29a5504",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c06bcee13c44d2a0af7376f2fb31d5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "a77c1437cf16482fac6aa75efe5fdd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191b2d29f22743a4b8e5d59195ec1b20",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6117a92e103940d5b8f90be2477d4742",
            "value": 1242
          }
        },
        "c77e7c6406ea488e93d469ef585a7aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c7b82a18c74025b4c911528b2d37e2",
            "placeholder": "​",
            "style": "IPY_MODEL_ce5134cff7994da78a0c0cffd1d29c22",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 68.7kB/s]"
          }
        },
        "d6f7195b32784f32ae57357e913e8aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d0885a1220c48359fb93a5fc29a5504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c06bcee13c44d2a0af7376f2fb31d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "191b2d29f22743a4b8e5d59195ec1b20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6117a92e103940d5b8f90be2477d4742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48c7b82a18c74025b4c911528b2d37e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce5134cff7994da78a0c0cffd1d29c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db71c65008fc45e3949aaf4f97bc4254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85b12d74dad743d8abdac2165deac1de",
              "IPY_MODEL_04495a348177422697e93bb76f74b812",
              "IPY_MODEL_4593b4a027f6403f88a4e41a10aadaab"
            ],
            "layout": "IPY_MODEL_436c1f7bd50147a49024ac45016abb6f"
          }
        },
        "85b12d74dad743d8abdac2165deac1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa52c54ae3294e5fbd5c9aa0c4d7cd3d",
            "placeholder": "​",
            "style": "IPY_MODEL_2e579551ce7a47818aef65ff967fed7a",
            "value": "vocab.txt: 100%"
          }
        },
        "04495a348177422697e93bb76f74b812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d9450b9fad4e2cb41a36f5a0e694ad",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_597f8b78c85145dd97fe8992a3071339",
            "value": 231508
          }
        },
        "4593b4a027f6403f88a4e41a10aadaab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d69f636652c47b1bfd7556be8dc784c",
            "placeholder": "​",
            "style": "IPY_MODEL_110a662f4ed3421684eda6bbcbbb66a4",
            "value": " 232k/232k [00:00&lt;00:00, 1.04MB/s]"
          }
        },
        "436c1f7bd50147a49024ac45016abb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa52c54ae3294e5fbd5c9aa0c4d7cd3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e579551ce7a47818aef65ff967fed7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5d9450b9fad4e2cb41a36f5a0e694ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "597f8b78c85145dd97fe8992a3071339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d69f636652c47b1bfd7556be8dc784c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "110a662f4ed3421684eda6bbcbbb66a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c917820573034b81a2e56e3ea894d04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43d449f57673405cbbb1a27939b83765",
              "IPY_MODEL_59a8e9328e154d7f9afe8ed8f9e7f052",
              "IPY_MODEL_e9df0633bb0642c991aaa922dacd9893"
            ],
            "layout": "IPY_MODEL_a84148ab152b4b41a4856597ae5e1b0a"
          }
        },
        "43d449f57673405cbbb1a27939b83765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35a09d139c04d368df55e1371a6723a",
            "placeholder": "​",
            "style": "IPY_MODEL_d839daec254640ecad1ed4235ca41ada",
            "value": "tokenizer.json: 100%"
          }
        },
        "59a8e9328e154d7f9afe8ed8f9e7f052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d500b92ddd148ca8a23e4bcf897bd35",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ab65ff142d64b978c5fd10f1f609551",
            "value": 711396
          }
        },
        "e9df0633bb0642c991aaa922dacd9893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aced207484d44131997e1ce78cbab875",
            "placeholder": "​",
            "style": "IPY_MODEL_0295d844fab743a7b0d0a88aa920a902",
            "value": " 711k/711k [00:00&lt;00:00, 2.69MB/s]"
          }
        },
        "a84148ab152b4b41a4856597ae5e1b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b35a09d139c04d368df55e1371a6723a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d839daec254640ecad1ed4235ca41ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d500b92ddd148ca8a23e4bcf897bd35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab65ff142d64b978c5fd10f1f609551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aced207484d44131997e1ce78cbab875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0295d844fab743a7b0d0a88aa920a902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec12ae25a07442fc8b873bca5e4195f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4523b10103be4bbfbb7147948f54fe4c",
              "IPY_MODEL_e118f127ca1240e68cdf875fc415cc73",
              "IPY_MODEL_0b7f941ca3084abf84ee906128469046"
            ],
            "layout": "IPY_MODEL_75704a673ec74f788dc52017a31c9ce3"
          }
        },
        "4523b10103be4bbfbb7147948f54fe4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3cbd82a48034e49ab40d829c74424f9",
            "placeholder": "​",
            "style": "IPY_MODEL_a90caf68425c47ae9bcbb074e9e565a1",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e118f127ca1240e68cdf875fc415cc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aae6f6041ea4781b62ff5d5ce77dbea",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c711ee9e7a5a4a848b2a439a208219f3",
            "value": 695
          }
        },
        "0b7f941ca3084abf84ee906128469046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aca333595d40413fa6c7a6b0f2e6fed8",
            "placeholder": "​",
            "style": "IPY_MODEL_1f1b6da1c6e842d3ac43a49c794c7c54",
            "value": " 695/695 [00:00&lt;00:00, 42.2kB/s]"
          }
        },
        "75704a673ec74f788dc52017a31c9ce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cbd82a48034e49ab40d829c74424f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a90caf68425c47ae9bcbb074e9e565a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2aae6f6041ea4781b62ff5d5ce77dbea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c711ee9e7a5a4a848b2a439a208219f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aca333595d40413fa6c7a6b0f2e6fed8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1b6da1c6e842d3ac43a49c794c7c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa3744a5458e405a919e25885c06227b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fc8a1a785c4432ebe7ad9cf9f4758ee",
              "IPY_MODEL_c2c3db6fc2714a868f90c38a6ccb42bf",
              "IPY_MODEL_95af06fb80024ab08fcf85c1f4ca198c"
            ],
            "layout": "IPY_MODEL_567c9237e6b44be6b2e859cbc5885d3f"
          }
        },
        "2fc8a1a785c4432ebe7ad9cf9f4758ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1c93076dd514aa6b9a0c1fc7b5cc796",
            "placeholder": "​",
            "style": "IPY_MODEL_b954cee3b2cd454baa4cce5f06561c77",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "c2c3db6fc2714a868f90c38a6ccb42bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d319f0e8c634c83b415e7e2de2ac4f3",
            "max": 297,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d79c15b979040cbb4161098c3f92c56",
            "value": 297
          }
        },
        "95af06fb80024ab08fcf85c1f4ca198c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34f9ccd1098046d5aff66b2a2f1f34ec",
            "placeholder": "​",
            "style": "IPY_MODEL_1384721dca3446639aac794daebd7a9c",
            "value": " 297/297 [00:00&lt;00:00, 18.2kB/s]"
          }
        },
        "567c9237e6b44be6b2e859cbc5885d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c93076dd514aa6b9a0c1fc7b5cc796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b954cee3b2cd454baa4cce5f06561c77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d319f0e8c634c83b415e7e2de2ac4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d79c15b979040cbb4161098c3f92c56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "34f9ccd1098046d5aff66b2a2f1f34ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1384721dca3446639aac794daebd7a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}